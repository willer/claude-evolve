#!/bin/bash
# Note: set -e removed - we handle errors explicitly with exit codes

# Source configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" &> /dev/null && pwd)"
source "$SCRIPT_DIR/../lib/config.sh"
source "$SCRIPT_DIR/../lib/csv-lock.sh"
source "$SCRIPT_DIR/../lib/ai-cli.sh"

# Setup logging to file
if [[ -n "${FULL_EVOLUTION_DIR:-}" ]]; then
  LOG_DIR="$FULL_EVOLUTION_DIR/logs"
  mkdir -p "$LOG_DIR"
  LOG_FILE="$LOG_DIR/worker-$$-$(date +%Y%m%d-%H%M%S).log"
  
  # Log to both terminal and file with timestamps
  exec > >(while IFS= read -r line; do echo "$(date '+%Y-%m-%d %H:%M:%S'): $line"; done | tee -a "$LOG_FILE") 2>&1
  echo "[WORKER-$$] Logging to: $LOG_FILE"
fi

# AIDEV-NOTE: Directory restoration helper to prevent working directory corruption
# Critical for preventing the bug where Ctrl+C during worker leaves the shell in wrong directory
# Helper to safely change directory with automatic restoration
safe_pushd() {
  SAFE_PUSHD_ORIGINAL_PWD=$(pwd)
  cd "$1" || return 1
  # Set trap to restore directory on any exit, error, or interrupt
  trap 'cd "$SAFE_PUSHD_ORIGINAL_PWD" 2>/dev/null || true' EXIT INT TERM ERR
}

safe_popd() {
  if [[ -n "${SAFE_PUSHD_ORIGINAL_PWD:-}" ]]; then
    cd "$SAFE_PUSHD_ORIGINAL_PWD" || true
    # Clear the trap since we're explicitly returning
    trap - EXIT INT TERM ERR
  fi
}

# Track current candidate for cleanup
CURRENT_CANDIDATE_ID=""
TERMINATION_SIGNAL=""

# Cleanup function to handle termination
cleanup_on_exit() {
  if [[ -n "$CURRENT_CANDIDATE_ID" ]]; then
    echo "[WORKER-$$] Worker terminated while processing $CURRENT_CANDIDATE_ID" >&2
    # Grab current status; only reset if it is not already a failure or complete
    echo "[WORKER-$$] Determining status before resetting" >&2

    local reset_output
    local reset_exit_code
    reset_output=$("$PYTHON_CMD" -c "
import sys
sys.path.insert(0, '$SCRIPT_DIR/..')
from lib.evolution_csv import EvolutionCSV
csv = EvolutionCSV('$FULL_CSV_PATH')
info = csv.get_candidate_info('$CURRENT_CANDIDATE_ID')
status = info.get('status', '').lower() if info else ''
print(f'Current status: {status}', file=sys.stderr)
# Do not reset if already failed, failed-ai-retry, or complete
if status and status not in ('complete', 'failed', 'failed-ai-retry', 'failed-parent-missing'):
    print(f'Resetting {status} -> pending', file=sys.stderr)
    csv.update_candidate_status('$CURRENT_CANDIDATE_ID', 'pending')
else:
    print(f'Status {status} does not need reset', file=sys.stderr)
" 2>&1)
    reset_exit_code=$?

    if [[ $reset_exit_code -ne 0 ]]; then
      echo "[WORKER-$$] Warning: Failed to reset status for $CURRENT_CANDIDATE_ID (exit code $reset_exit_code)" >&2
      echo "[WORKER-$$] Error details: $reset_output" >&2
    else
      echo "[WORKER-$$] Status check result: $reset_output" >&2
    fi
  fi
}

# Set up signal handlers
trap 'TERMINATION_SIGNAL="TERM"; cleanup_on_exit' TERM
trap 'TERMINATION_SIGNAL="INT"; cleanup_on_exit' INT
trap 'TERMINATION_SIGNAL="HUP"; cleanup_on_exit' HUP
trap 'cleanup_on_exit' EXIT

# Parse arguments first to get config path
timeout_seconds=""
config_path=""
while [[ $# -gt 0 ]]; do
  case "$1" in
    --timeout)
      timeout_seconds="$2"
      shift 2
      ;;
    --config)
      config_path="$2"
      shift 2
      ;;
    *)
      echo "[ERROR] Unknown argument: $1" >&2
      exit 1
      ;;
  esac
done

# Load config using the provided path, environment variable, or default
if [[ -n $config_path ]]; then
  load_config "$config_path"
elif [[ -n ${CLAUDE_EVOLVE_CONFIG:-} ]]; then
  load_config "$CLAUDE_EVOLVE_CONFIG"
else
  load_config
fi

# AI random selection function for code evolution
call_ai_for_evolution() {
  local prompt="$1"
  local candidate_id="$2"

  # Get target file path from worker context
  local target_file="$FULL_OUTPUT_DIR/evolution_${candidate_id}.py"

  # Capture file state before AI call
  local file_hash_before=""
  local file_mtime_before=""
  if [[ -f "$target_file" ]]; then
    file_hash_before=$(shasum -a 256 "$target_file" 2>/dev/null | cut -d' ' -f1)
    file_mtime_before=$(stat -f %m "$target_file" 2>/dev/null || stat -c %Y "$target_file" 2>/dev/null)
  fi

  # Use the centralized AI library for evolution (random model selection)
  local ai_output
  ai_output=$(call_ai_random "$prompt" "run")
  local ai_exit_code=$?

  # Check if the target file was actually modified
  local file_was_modified=false
  if [[ -f "$target_file" ]]; then
    local file_hash_after
    local file_mtime_after
    file_hash_after=$(shasum -a 256 "$target_file" 2>/dev/null | cut -d' ' -f1)
    file_mtime_after=$(stat -f %m "$target_file" 2>/dev/null || stat -c %Y "$target_file" 2>/dev/null)

    if [[ "$file_hash_before" != "$file_hash_after" ]] || [[ "$file_mtime_before" != "$file_mtime_after" ]]; then
      file_was_modified=true
    fi
  fi

  # Success only if the target file was actually modified.
  # Even if AI exited with code 0, if there were no changes, treat as failure to avoid stale copies.
  if [[ "$file_was_modified" == "true" ]]; then
    echo "[WORKER-$$] AI successfully modified $target_file (exit code: $ai_exit_code)" >&2
    return 0
  fi

  # No modification detected; clean up the copied file
  echo "[WORKER-$$] AI changed nothing or failed; cleaning up temporary file" >&2
  rm -f "$target_file"
  echo "[WORKER-$$] AI failed: exit code $ai_exit_code, no file changes detected" >&2
  return 1
}

# Validate paths
if [[ ! -f "$FULL_CSV_PATH" ]]; then
  echo "[WORKER-$$] CSV file not found: $FULL_CSV_PATH" >&2
  exit 1
fi

# Process a single candidate
process_candidate() {
  local candidate_id="$1"
  local parent_id="$2"
  local description="$3"
  
  echo "[WORKER-$$] Processing candidate ID: $candidate_id"
  echo "[WORKER-$$] Description: $description"
  echo "[WORKER-$$] Based on ID: $parent_id"
  
  # Treat "baseline-000" parent ID as empty/baseline
  if [[ "$parent_id" == "baseline-000" ]]; then
    parent_id=""
    echo "[WORKER-$$] Parent ID 'baseline-000' treated as baseline (empty parent)"
  fi

  # Handle multi-parent IDs - extract first valid parent
  # Use global variable so caller can access resolved parent for recursive processing
  RESOLVED_PARENT_ID=""
  if [[ -n "$parent_id" ]]; then
    # Split by comma or space and try each parent in order
    IFS=$',; ' read -ra parent_candidates <<< "$parent_id"
    for candidate_parent in "${parent_candidates[@]}"; do
      # Trim whitespace
      candidate_parent="${candidate_parent// /}"
      if [[ -z "$candidate_parent" ]]; then
        continue
      fi

      # Check if this parent file exists
      local test_file="$FULL_OUTPUT_DIR/evolution_${candidate_parent}.py"
      if [[ -f "$test_file" ]]; then
        RESOLVED_PARENT_ID="$candidate_parent"
        echo "[WORKER-$$] Resolved multi-parent '$parent_id' -> '$RESOLVED_PARENT_ID'"
        break
      fi
    done

    # If no valid parent found, fail
    if [[ -z "$RESOLVED_PARENT_ID" ]]; then
      echo "[WORKER-$$] ERROR: None of the parent algorithms found for: $parent_id" >&2
      echo "[WORKER-$$] Attempted parents: ${parent_candidates[*]}" >&2
      return 78 # Exit code for missing parent
    fi
  fi

  # Determine source algorithm
  local source_file
  if [[ -z "$RESOLVED_PARENT_ID" ]]; then
    echo "[WORKER-$$] Using base algorithm"
    source_file="$FULL_ALGORITHM_PATH"
  else
    echo "[WORKER-$$] Using parent algorithm: $RESOLVED_PARENT_ID"
    source_file="$FULL_OUTPUT_DIR/evolution_${RESOLVED_PARENT_ID}.py"
  fi

  # Check if this is a baseline candidate (no parent and specific ID pattern)
  local is_baseline=false
  if [[ -z "$RESOLVED_PARENT_ID" ]] && [[ "$candidate_id" =~ ^(baseline|baseline-000|000|0|gen00-000)$ ]]; then
    is_baseline=true
    echo "[WORKER-$$] Detected baseline candidate - will run algorithm.py directly"
  fi
  
  # Target file for evolution (not used for baseline)
  local target_file="$FULL_OUTPUT_DIR/evolution_${candidate_id}.py"
  
  # Check if processing should be skipped
  if [[ "$is_baseline" == "true" ]]; then
    # For baseline, skip all file operations
    echo "[WORKER-$$] Baseline candidate - skipping file operations"
  elif [[ -f "$target_file" ]]; then
    echo "[WORKER-$$] ï¿½  Skipping copy - File already exists - skipping all processing"
    echo "[WORKER-$$] ï¿½  Skipping Claude processing - File already exists - skipping all processing"
    
    # Check if already evaluated
    local current_status
    current_status=$("$PYTHON_CMD" -c "
import sys
sys.path.insert(0, '$SCRIPT_DIR/..')
from lib.evolution_csv import EvolutionCSV
with EvolutionCSV('$FULL_CSV_PATH') as csv:
    candidate = csv.get_candidate_info('$candidate_id')
    if candidate:
        print(candidate.get('status', 'unknown'))
    else:
        print('unknown')
")
    
    if [[ "$current_status" == "complete" ]]; then
      echo "[WORKER-$$] Already evaluated - skipping"
      # Reset status back to complete since get_next_pending_candidate() set it to running
      if ! "$PYTHON_CMD" -c "
import sys
sys.path.insert(0, '$SCRIPT_DIR/..')
from lib.evolution_csv import EvolutionCSV
with EvolutionCSV('$FULL_CSV_PATH') as csv:
    success = csv.update_candidate_status('$candidate_id', 'complete')
    if not success:
        print(f'ERROR: Failed to update status for $candidate_id', file=sys.stderr)
        sys.exit(1)
"; then
        echo "[WORKER-$$] ERROR: Failed to reset status to complete for $candidate_id" >&2
        # Don't clear CURRENT_CANDIDATE_ID so cleanup handler can try again
        return 1
      fi

      echo "[WORKER-$$] Status confirmed as complete"
      # Clear CURRENT_CANDIDATE_ID before returning to prevent cleanup from interfering
      CURRENT_CANDIDATE_ID=""
      return 0
    fi
    
    # Run evaluation only
    echo "[WORKER-$$] Running evaluation..."
  else
    # Copy source to target
    echo "[WORKER-$$] Copying $source_file to $target_file"
    cp "$source_file" "$target_file"
    
    # Apply evolution using AI
    echo "[WORKER-$$] Applying evolution..."
    
    # Use relative path for AI prompt
    local target_basename=$(basename "$target_file")
    local evolution_prompt="$(get_git_protection_warning)

Modify the algorithm in $target_basename based on this description: $description

The modification should be substantial and follow the description exactly. Make sure the algorithm still follows all interface requirements and can run properly.

Important: Make meaningful changes that match the description. Don't just add comments or make trivial adjustments.

IMPORTANT: If you need to read Python (.py) or CSV files, read them in chunks using offset and limit parameters to avoid context overload
Example: Read(file_path='evolution_gen01-001.py', offset=0, limit=100) then Read(offset=100, limit=100), etc.
This is especially important for models with smaller context windows (like GLM).

CRITICAL: If you do not know how to implement what was asked for, or if the requested change is unclear or not feasible, you MUST refuse to make any changes. DO NOT modify the code if you are uncertain about the implementation. Simply respond that you cannot implement the requested change and explain why. It is better to refuse than to make incorrect or random changes."

    if [[ "$is_baseline" != "true" ]]; then
      # Change to evolution directory so AI can access files (with safe restoration on interrupt)
      safe_pushd "$FULL_EVOLUTION_DIR" || {
        echo "[WORKER-$$] ERROR: Failed to change to evolution directory" >&2
        rm -f "$target_file"
        return 1
      }

      # Call AI with random model selection
      if ! call_ai_for_evolution "$evolution_prompt" "$candidate_id"; then
        echo "[WORKER-$$] ERROR: AI model failed to generate code - leaving as pending for retry" >&2
        safe_popd
        rm -f "$target_file"  # Clean up on failure
        # Return with special code to indicate AI failure (should remain pending)
        return 77
      fi

      # Restore working directory
      safe_popd
      
      echo "[WORKER-$$] Evolution applied successfully"
      
      # Record which AI model generated the code (regardless of evaluation outcome)
      if [[ -n "${SUCCESSFUL_RUN_MODEL:-}" ]]; then
        echo "[WORKER-$$] Recording that $SUCCESSFUL_RUN_MODEL generated the code" >&2
        "$PYTHON_CMD" -c "
import sys
sys.path.insert(0, '$SCRIPT_DIR/..')
from lib.evolution_csv import EvolutionCSV
with EvolutionCSV('$FULL_CSV_PATH') as csv:
    csv.update_candidate_field('$candidate_id', 'run-LLM', '$SUCCESSFUL_RUN_MODEL')
" || echo "[WORKER-$$] Warning: Failed to record run-LLM field" >&2
      fi
      
      # Check if the generated Python file has syntax errors
      echo "[WORKER-$$] Checking Python syntax..." >&2
      if ! "$PYTHON_CMD" -m py_compile "$target_file" 2>&1; then
        echo "[WORKER-$$] ERROR: Generated Python file has syntax errors!" >&2
        echo "[WORKER-$$] File: $target_file" >&2
        # Delete the problematic Python file
        rm -f "$target_file"
        echo "[WORKER-$$] Deleted corrupted algorithm file: $target_file" >&2
        # Set status to pending for retry
        update_candidate_status "$candidate_id" "pending"
        # Clear CURRENT_CANDIDATE_ID before returning
        CURRENT_CANDIDATE_ID=""
        # Return 0 to indicate that this specific processing step is handled,
        # and the candidate is now pending for a future retry.
        return 0
      fi
    fi
  fi
  
  # Run evaluation
  echo "[WORKER-$$] Evaluating algorithm..."
  local eval_output_file="$FULL_EVOLUTION_DIR/temp-eval-$$-$candidate_id.out"
  local eval_start=$(date +%s)
  
  # Prepare evaluation command
  # For baseline, pass "baseline" or empty string to evaluator to use algorithm.py
  local eval_arg="$candidate_id"
  if [[ "$is_baseline" == "true" ]]; then
    # Evaluator should interpret this as "use algorithm.py directly"
    eval_arg=""
  fi
  local eval_cmd=("$PYTHON_CMD" "$FULL_EVALUATOR_PATH" "$eval_arg")

  # Add memory limiting if configured
  # CRITICAL: Use multiple layers of protection (ulimit + Python wrapper + monitoring)
  local memory_protection=""
  if [[ -n "$MEMORY_LIMIT_MB" ]] && [[ "$MEMORY_LIMIT_MB" -gt 0 ]]; then
    # Layer 1: ulimit for hard memory limit (kernel-enforced)
    # IMPORTANT: Use -m (RSS) not -v (virtual memory) because:
    # - Neural networks use mmap() which bypasses RLIMIT_AS (-v)
    # - RSS limit is more reliable for actual memory consumption
    # Convert MB to KB for ulimit
    local memory_limit_kb=$((MEMORY_LIMIT_MB * 1024))

    # Try -m first (RSS limit), fall back to -v if not supported
    if ulimit -m $memory_limit_kb 2>/dev/null; then
      memory_protection="ulimit -m $memory_limit_kb 2>/dev/null; "
      echo "[MEMORY] Layer 1: ulimit -m ${memory_limit_kb}KB (RSS limit - catches neural networks)" >&2
    else
      memory_protection="ulimit -v $memory_limit_kb 2>/dev/null; "
      echo "[MEMORY] Layer 1: ulimit -v ${memory_limit_kb}KB (fallback - may not catch neural networks)" >&2
    fi

    # Layer 2: Python wrapper with PROCESS TREE monitoring (backup protection)
    eval_cmd=("$PYTHON_CMD" "$SCRIPT_DIR/../lib/memory_limit_wrapper.py" "$MEMORY_LIMIT_MB" "${eval_cmd[@]}")

    echo "[MEMORY] Layer 2: Python process tree monitoring (kills entire subprocess tree)" >&2
  fi

  # Add timeout if configured
  [[ -n "$timeout_seconds" ]] && eval_cmd=(timeout "$timeout_seconds" "${eval_cmd[@]}")

  # Run evaluation with memory protection, tee to both display and capture output
  # Use stdbuf to disable buffering for real-time output
  # IMPORTANT: Use PIPESTATUS to get the exit code of the evaluation command, not tee
  # The subshell ensures ulimit is applied before the command runs
  stdbuf -o0 -e0 bash -c "${memory_protection}$(printf '%q ' "${eval_cmd[@]}")" 2>&1 | tee "$eval_output_file" >&2
  local eval_exit_code=${PIPESTATUS[0]}  # Get exit code of first command in pipe
  
  if [[ $eval_exit_code -eq 0 ]]; then
    local eval_end=$(date +%s)
    local eval_duration=$((eval_end - eval_start))
    
    # Read captured output for parsing
    eval_output=$(<"$eval_output_file")
    
    # Extract performance score - support multiple formats
    # Try to parse the output and extract score
    local score_and_json=$("$PYTHON_CMD" -c "
import sys
import json
import re

output = '''$eval_output'''

# Try different formats
score = None
json_data = None

# Format 1: Simple numeric value (just a number on a line)
for line in output.strip().split('\n'):
    line = line.strip()
    if line and not line.startswith('{'):
        try:
            score = float(line)
            break
        except ValueError:
            pass

# Format 2: JSON with 'performance' or 'score' field
if score is None:
    for line in output.strip().split('\n'):
        line = line.strip()
        if line.startswith('{'):
            try:
                data = json.loads(line)
                json_data = data
                if 'performance' in data:
                    score = float(data['performance'])
                elif 'score' in data:
                    score = float(data['score'])
                break
            except (json.JSONDecodeError, ValueError, KeyError):
                pass

# Format 3: SCORE: prefix (backward compatibility)
if score is None:
    match = re.search(r'^SCORE:\s*([+-]?\d*\.?\d+)', output, re.MULTILINE)
    if match:
        try:
            score = float(match.group(1))
        except ValueError:
            pass

# Output results
if score is not None:
    print(f'SCORE={score}')
    if json_data:
        print('JSON_DATA=' + json.dumps(json_data))
else:
    print('SCORE=NONE')
")
    
    # Parse the Python output
    local score=""
    local json_data=""
    while IFS= read -r line; do
      if [[ "$line" =~ ^SCORE=(.*)$ ]]; then
        score="${BASH_REMATCH[1]}"
      elif [[ "$line" =~ ^JSON_DATA=(.*)$ ]]; then
        json_data="${BASH_REMATCH[1]}"
      fi
    done <<< "$score_and_json"
    
    if [[ "$score" != "NONE" ]] && [[ -n "$score" ]]; then
      echo "[WORKER-$$] Evaluation complete: score=$score (${eval_duration}s)"
      
      # Update CSV with result
      if [[ -n "$json_data" ]]; then
        # If we have JSON data, update all fields
        "$PYTHON_CMD" -c "
import sys
import json
sys.path.insert(0, '$SCRIPT_DIR/..')
from lib.evolution_csv import EvolutionCSV

json_data = json.loads('$json_data')
with EvolutionCSV('$FULL_CSV_PATH') as csv:
    csv.update_candidate_status('$candidate_id', 'complete')
    # Update all fields from JSON
    for key, value in json_data.items():
        csv.update_candidate_field('$candidate_id', key, str(value))
"
      else
        # Simple score only
        "$PYTHON_CMD" -c "
import sys
sys.path.insert(0, '$SCRIPT_DIR/..')
from lib.evolution_csv import EvolutionCSV
with EvolutionCSV('$FULL_CSV_PATH') as csv:
    csv.update_candidate_status('$candidate_id', 'complete')
    csv.update_candidate_performance('$candidate_id', '$score')
"
      fi
    else
      echo "[WORKER-$$] ERROR: No score found in evaluation output" >&2
      echo "[WORKER-$$] Output: $eval_output" >&2
      # rm -f "$eval_output_file"  # Keep for debugging
      echo "[WORKER-$$] Evaluation output saved to: $eval_output_file" >&2
      # Clear CURRENT_CANDIDATE_ID before returning
      CURRENT_CANDIDATE_ID=""
      return 1
    fi
    
    # Clean up temp file (comment out to keep for debugging)
    # rm -f "$eval_output_file"
    echo "[WORKER-$$] Evaluation output saved to: $eval_output_file" >&2
    
    # Clear CURRENT_CANDIDATE_ID on successful completion
    CURRENT_CANDIDATE_ID=""
  else
    local exit_code=$eval_exit_code
    # Read any output that was captured before failure
    eval_output=$(<"$eval_output_file")
    # rm -f "$eval_output_file"  # Keep for debugging
    echo "[WORKER-$$] Evaluation output saved to: $eval_output_file" >&2
    
    echo "[WORKER-$$] ERROR: Evaluation failed with exit code $exit_code" >&2
    echo "[WORKER-$$] Output: $eval_output" >&2
    
    # Mark as failed in CSV
    echo "[WORKER-$$] Marking $candidate_id as failed in CSV" >&2
    if ! "$PYTHON_CMD" -c "
import sys
sys.path.insert(0, '$SCRIPT_DIR/..')
from lib.evolution_csv import EvolutionCSV
try:
    with EvolutionCSV('$FULL_CSV_PATH') as csv:
        success = csv.update_candidate_status('$candidate_id', 'failed')
        if not success:
            print(f'ERROR: Failed to update status for {candidate_id}', file=sys.stderr)
            sys.exit(1)
except Exception as e:
    print(f'ERROR: Exception updating status: {e}', file=sys.stderr)
    sys.exit(1)
" 2>&1; then
      echo "[WORKER-$$] ERROR: Failed to update CSV status to failed" >&2
    else
      echo "[WORKER-$$] Successfully marked $candidate_id as failed" >&2
    fi
    
    # Clear CURRENT_CANDIDATE_ID before returning to prevent cleanup handler from resetting it
    CURRENT_CANDIDATE_ID=""
    return $exit_code
  fi
}

# Don't reset running candidates on startup - they might be legitimately being processed by another worker

# Main worker loop
echo "[WORKER-$$] Worker started (will exit after $WORKER_MAX_CANDIDATES candidates)"

# Track candidates processed for self-termination
candidates_processed=0

while true; do
  # Debug: Show current status of all candidates
  echo "[WORKER-$$] Current candidate statuses:" >&2
  "$PYTHON_CMD" -c "
import sys
sys.path.insert(0, '$SCRIPT_DIR/..')
from lib.evolution_csv import EvolutionCSV
with EvolutionCSV('$FULL_CSV_PATH') as csv:
    rows = csv._read_csv()
    if rows:
        start_idx = 1 if rows and rows[0] and rows[0][0].lower() == 'id' else 0
        status_count = {}
        running_candidates = []
        for row in rows[start_idx:]:
            if len(row) > 4:
                status = row[4].strip() or 'pending'
                status_count[status] = status_count.get(status, 0) + 1
                if status == 'running':
                    candidate_id = row[0].strip().strip('\"') if len(row) > 0 else '?'
                    running_candidates.append(candidate_id)
        print(f'Status counts: {status_count}', file=sys.stderr)
        if running_candidates:
            print(f'Running candidates: {running_candidates}', file=sys.stderr)
" 2>&1 || true

  # Try to claim a pending candidate
  candidate_info=$("$PYTHON_CMD" -c "
import sys
sys.path.insert(0, '$SCRIPT_DIR/..')
from lib.evolution_csv import EvolutionCSV
with EvolutionCSV('$FULL_CSV_PATH') as csv:
    result = csv.get_next_pending_candidate()
    if result:
        candidate_id, _ = result
        # Get full candidate info
        candidate = csv.get_candidate_info(candidate_id)
        if candidate:
            print(f'{candidate[\"id\"]}|{candidate.get(\"basedOnId\", \"\")}|{candidate[\"description\"]}')
")
  
  if [[ -z "$candidate_info" ]]; then
    # No pending work
    break
  fi
  
  # Parse candidate info
  IFS='|' read -r candidate_id parent_id description <<< "$candidate_info"
  
  # Set current candidate for cleanup
  CURRENT_CANDIDATE_ID="$candidate_id"

  # Process the candidate and capture exit code
  process_candidate "$candidate_id" "$parent_id" "$description"
  process_exit_code=$?
  
  if [[ $process_exit_code -eq 0 ]]; then
    echo "[WORKER-$$] Successfully processed $candidate_id"
  elif [[ $process_exit_code -eq 77 ]]; then
    # AI generation failed, mark for retry
    echo "[WORKER-$$] AI generation failed for $candidate_id - marking as failed-ai-retry"
    "$PYTHON_CMD" -c "
import sys
sys.path.insert(0, '$SCRIPT_DIR/..')
from lib.evolution_csv import EvolutionCSV
with EvolutionCSV('$FULL_CSV_PATH') as csv:
    csv.update_candidate_status('$candidate_id', 'failed-ai-retry')
" 2>/dev/null || true
  elif [[ $process_exit_code -eq 78 ]]; then
    # Missing parent; mark child as failed and immediately process parent
    # Use RESOLVED_PARENT_ID which was set by process_candidate
    actual_parent_id="${RESOLVED_PARENT_ID:-$parent_id}"

    echo "[WORKER-$$] Parent '$actual_parent_id' missing for $candidate_id"
    echo "[WORKER-$$] Marking $candidate_id as failed-parent-missing"

    "$PYTHON_CMD" -c "
import sys
sys.path.insert(0, '$SCRIPT_DIR/..')
from lib.evolution_csv import EvolutionCSV
with EvolutionCSV('$FULL_CSV_PATH') as csv:
    # Mark child as failed
    csv.update_candidate_status('$candidate_id', 'failed-parent-missing')
" 2>/dev/null || true

    # Get parent info to process it immediately
    parent_info=$("$PYTHON_CMD" -c "
import sys
sys.path.insert(0, '$SCRIPT_DIR/..')
from lib.evolution_csv import EvolutionCSV
with EvolutionCSV('$FULL_CSV_PATH') as csv:
    parent = csv.get_candidate_info('$actual_parent_id')
    if parent:
        status = parent.get('status', '').lower()
        parent_of_parent = parent.get('basedOnId', '')
        description = parent.get('description', '')
        # Output: status|parent_of_parent|description
        print(f\"{status}|{parent_of_parent}|{description}\")
")

    if [[ -n "$parent_info" ]]; then
      IFS='|' read -r parent_status parent_of_parent parent_description <<< "$parent_info"

      # Only process if parent needs processing
      if [[ "$parent_status" == "" || "$parent_status" == "pending" || "$parent_status" == "skipped" || "$parent_status" == "failed-parent-missing" ]]; then
        echo "[WORKER-$$] Immediately processing parent '$actual_parent_id' (status: $parent_status)"

        # Mark parent as running
        "$PYTHON_CMD" -c "
import sys
sys.path.insert(0, '$SCRIPT_DIR/..')
from lib.evolution_csv import EvolutionCSV
with EvolutionCSV('$FULL_CSV_PATH') as csv:
    csv.update_candidate_status('$actual_parent_id', 'running')
" 2>/dev/null || true

        # Clear current candidate (parent processing will set its own)
        CURRENT_CANDIDATE_ID=""

        # Process parent recursively
        process_candidate "$actual_parent_id" "$parent_of_parent" "$parent_description"
        parent_exit_code=$?

        if [[ $parent_exit_code -eq 0 ]]; then
          echo "[WORKER-$$] Successfully processed parent '$actual_parent_id'"
          # Now the child can potentially be retried (user can reset failed-parent-missing later)
        else
          echo "[WORKER-$$] Failed to process parent '$actual_parent_id' (exit code: $parent_exit_code)"
        fi
      else
        echo "[WORKER-$$] Parent '$actual_parent_id' has status '$parent_status' - not processing"
      fi
    else
      echo "[WORKER-$$] Warning: parent '$actual_parent_id' not found in CSV"
    fi

    # Clear current candidate and continue to next
    CURRENT_CANDIDATE_ID=""
  else
    echo "[WORKER-$$] Failed to process $candidate_id"
    # Other failures (evaluation errors, etc) mark as failed
    "$PYTHON_CMD" -c "
import sys
sys.path.insert(0, '$SCRIPT_DIR/..')
from lib.evolution_csv import EvolutionCSV
with EvolutionCSV('$FULL_CSV_PATH') as csv:
    csv.update_candidate_status('$candidate_id', 'failed')
" 2>/dev/null || true
  fi
  
  # Clear current candidate
  CURRENT_CANDIDATE_ID=""
  
  # Increment counter and check for self-termination
  candidates_processed=$((candidates_processed + 1))
  echo "[WORKER-$$] Processed $candidates_processed/$WORKER_MAX_CANDIDATES candidates"
  
  if [[ $candidates_processed -ge $WORKER_MAX_CANDIDATES ]]; then
    echo "[WORKER-$$] Reached maximum candidates ($WORKER_MAX_CANDIDATES), exiting for refresh"
    break
  fi
done

echo "[WORKER-$$] No more pending candidates, worker exiting"
