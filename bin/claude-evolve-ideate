#!/bin/bash

set -e

# Load configuration
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
# shellcheck source=../lib/config.sh
source "$SCRIPT_DIR/../lib/config.sh"
# shellcheck source=../lib/csv-lock.sh
source "$SCRIPT_DIR/../lib/csv-lock.sh"
# shellcheck source=../lib/ai-cli.sh
source "$SCRIPT_DIR/../lib/ai-cli.sh"

# Use CLAUDE_EVOLVE_CONFIG if set, otherwise default
if [[ -n ${CLAUDE_EVOLVE_CONFIG:-} ]]; then
  load_config "$CLAUDE_EVOLVE_CONFIG"
else
  # Check if config.yaml exists in current directory
  if [[ -f "config.yaml" ]]; then
    # Don't export to avoid collision with parallel runs
    CONFIG_FILE="$(pwd)/config.yaml"
    load_config "$CONFIG_FILE"
  else
    load_config
  fi
fi

# Setup logging to file
if [[ -n "${FULL_EVOLUTION_DIR:-}" ]]; then
  LOG_DIR="$FULL_EVOLUTION_DIR/logs"
  mkdir -p "$LOG_DIR"
  LOG_FILE="$LOG_DIR/ideate-$$-$(date +%Y%m%d-%H%M%S).log"
  
  # Log to both terminal and file with timestamps
  exec > >(while IFS= read -r line; do echo "$(date '+%Y-%m-%d %H:%M:%S'): $line"; done | tee -a "$LOG_FILE") 2>&1
  echo "[IDEATE-$$] Logging to: $LOG_FILE"
fi

# Helper function to call AI with limit check
call_ai_with_limit_check() {
  local prompt="$1"
  local generation="${2:-01}"  # Default to generation 01 if not provided
  
  # Calculate hash value for round-robin based on generation
  local gen_num
  if [[ $generation =~ ^0*([0-9]+)$ ]]; then
    gen_num=$((10#${BASH_REMATCH[1]}))
  else
    gen_num=1
  fi
  
  # Use centralized AI library for ideation
  local ai_output
  ai_output=$(call_ai_with_round_robin "$prompt" "ideate" "$gen_num")
  local ai_exit_code=$?
  
  # Handle special exit codes
  if [[ $ai_exit_code -eq 3 ]]; then
    # All models hit usage limits
    echo -e "\033[31m[ERROR] ALL AI MODELS HIT USAGE LIMITS!\033[0m" >&2
    echo -e "\033[31m[ERROR] Ideation halted due to API rate limits.\033[0m" >&2
    echo -e "\033[33m[INFO] Please wait for the rate limits to reset before continuing.\033[0m" >&2
    echo -e "\033[33m[INFO] No ideas were generated. Run ideate again when the limits reset.\033[0m" >&2
    exit 1
  fi
  
  if [[ $ai_exit_code -eq 0 ]]; then
    # For ideation, AI modifies files directly - just return success
    echo "[INFO] AI succeeded" >&2
    return 0
  else
    return $ai_exit_code
  fi
}


# Backward compatibility alias
call_claude_with_limit_check() {
  call_ai_with_limit_check "$@"
}

# Robust AI calling with fallbacks across all available models
# Returns 0 on success and echoes the successful model name to stdout
call_ai_for_ideation() {
  local prompt="$1"
  local generation="${2:-01}"
  local expected_count="${3:-1}"  # Number of ideas expected to be added
  local temp_csv_file="${4:-temp-csv-$$.csv}"  # Optional temp CSV filename
  
  # Calculate hash value for round-robin based on generation
  local gen_num
  if [[ $generation =~ ^0*([0-9]+)$ ]]; then
    gen_num=$((10#${BASH_REMATCH[1]}))
  else
    gen_num=1
  fi
  
  # Make a backup of the pre-populated temp CSV (which includes stub rows from caller)
  # This preserves the stub rows that the caller added
  local temp_csv_backup="${temp_csv_file}.backup"
  if [[ -f "$temp_csv_file" ]]; then
    cp "$temp_csv_file" "$temp_csv_backup"
  else
    echo "[ERROR] Temp CSV file not found at start: $temp_csv_file" >&2
    return 1
  fi

  # Get the current row count before any modifications (from the pre-populated file with stubs)
  local original_csv_count
  original_csv_count=$(grep -v '^[[:space:]]*$' "$temp_csv_file" | tail -n +2 | wc -l | tr -d '[:space:]')

  echo "[DEBUG] Pre-populated temp CSV has $original_csv_count rows (includes stub rows with placeholders)" >&2

  # Get models for ideation
  local model_list
  model_list=$(get_models_for_command "ideate")
  local models=()
  read -ra models <<< "$model_list"

  if [[ ${#models[@]} -eq 0 ]]; then
    echo "[ERROR] No models configured for ideation" >&2
    rm -f "$temp_csv_backup"
    return 1
  fi

  # Calculate starting index for round-robin
  local num_models=${#models[@]}
  local start_index=$((gen_num % num_models))

  # Create ordered list based on round-robin
  local ordered_models=()
  for ((i=0; i<num_models; i++)); do
    local idx=$(((start_index + i) % num_models))
    ordered_models+=("${models[$idx]}")
  done

  echo "[AI] Model order for ideate (round-robin): ${ordered_models[*]}" >&2

  # Try each model until CSV changes
  for model in "${ordered_models[@]}"; do
    echo "[AI] Attempting ideate with $model" >&2

    # Restore temp CSV from backup before each attempt (in case previous model corrupted it)
    # This preserves the stub rows that the caller pre-populated
    cp "$temp_csv_backup" "$temp_csv_file"

    # Call the model directly
    local ai_output
    ai_output=$(call_ai_model_configured "$model" "$prompt")
    local ai_exit_code=$?

    # Check if the file was modified correctly
    if [[ -f "$temp_csv_file" ]]; then
      local new_csv_count
      new_csv_count=$(grep -v '^[[:space:]]*$' "$temp_csv_file" | tail -n +2 | wc -l | tr -d '[:space:]')
      local added_count=$((new_csv_count - original_csv_count))

      echo "[DEBUG] After $model: original=$original_csv_count, new=$new_csv_count, added=$added_count" >&2

      # Check if row count is correct (should be same since we're editing stubs, not adding)
      if [[ $new_csv_count -eq $original_csv_count ]]; then
        # Count remaining placeholders - there should be none if AI did its job
        local placeholder_count
        placeholder_count=$(grep -c "PLACEHOLDER" "$temp_csv_file" 2>/dev/null || echo "0")
        # Strip whitespace and ensure we have a clean integer
        placeholder_count=$(echo "$placeholder_count" | tr -d '[:space:]')
        placeholder_count=${placeholder_count:-0}

        if [[ $placeholder_count -eq 0 ]]; then
          echo "[INFO] CSV modified by $model: filled $expected_count placeholder rows ✓" >&2

          # Post-process to ensure all description fields are quoted
          local fixed_csv_file="${temp_csv_file}.fixed"

          # Use the CSV fixer script
          if "$PYTHON_CMD" "$SCRIPT_DIR/../lib/csv_fixer.py" "$temp_csv_file" "$fixed_csv_file"; then
            mv "$fixed_csv_file" "$temp_csv_file"
            echo "[INFO] CSV format validated and fixed if needed" >&2
          else
            echo "[WARN] CSV format validation failed, using original" >&2
          fi

          # Clean up backup file
          rm -f "$temp_csv_backup"

          # Echo the successful model name for caller to capture
          echo "$model"
          return 0
        else
          echo "[WARN] $model left $placeholder_count placeholders unfilled - trying next model" >&2
          # Continue to next model
        fi
      elif [[ $added_count -lt 0 ]]; then
        echo "[WARN] $model deleted rows ($added_count) - trying next model" >&2
        # Continue to next model
      elif [[ $added_count -gt 0 ]]; then
        echo "[WARN] $model added extra rows ($added_count) instead of editing stubs - trying next model" >&2
        # Continue to next model
      else
        echo "[INFO] CSV unchanged after $model (exit code: $ai_exit_code)" >&2
        # Log last few lines of AI output to help debug why it succeeded but didn't change the file
        if [[ -n "$ai_output" ]]; then
          echo "[AI] Last 10 lines of $model output:" >&2
          echo "$ai_output" | tail -n 10 >&2
          echo "[AI] ---" >&2
        fi
        # Continue to next model
      fi
    else
      echo "[INFO] Temp CSV file not found after $model: $temp_csv_file" >&2
      # Continue to next model
    fi
  done
  
  # All models tried, none changed the file
  rm -f "$temp_csv_backup"
  echo "[ERROR] All AI models failed to generate ideas" >&2
  return 1
}

# Parse arguments
use_strategies=true

while [[ $# -gt 0 ]]; do
  case $1 in
  --help)
    cat <<EOF
claude-evolve ideate - Generate new algorithm ideas using evolutionary strategies

USAGE:
  claude-evolve ideate [--legacy N]

OPTIONS:
  --legacy N  Use legacy mode with N ideas (ignores strategy config)
  --help      Show this help message

DESCRIPTION:
  Generates algorithm ideas using multi-strategy evolutionary approach:
  - Novel exploration: Pure creativity, global search
  - Hill climbing: Parameter tuning of top performers  
  - Structural mutation: Algorithmic changes to top performers
  - Crossover hybrid: Combine successful approaches
  
  Strategy distribution is configured in evolution/config.yaml
EOF
    exit 0
    ;;
  --legacy)
    use_strategies=false
    shift
    if [[ $1 =~ ^[0-9]+$ ]]; then
      TOTAL_IDEAS=$1
      shift
    else
      echo "[ERROR] --legacy requires a number" >&2
      exit 1
    fi
    ;;
  *)
    echo "[ERROR] Unknown option: $1" >&2
    exit 1
    ;;
  esac
done

# Check workspace using config
if [[ ! -d "$FULL_EVOLUTION_DIR" ]]; then
  echo "[ERROR] Evolution workspace not found: $FULL_EVOLUTION_DIR. Run 'claude-evolve setup' first." >&2
  exit 1
fi

# Ensure CSV exists
if [[ ! -f "$FULL_CSV_PATH" ]]; then
  echo "id,basedOnId,description,performance,status,idea-LLM,run-LLM" >"$FULL_CSV_PATH"
fi

# Validate strategy configuration
if [[ $use_strategies == true ]]; then
  total_check=$((NOVEL_EXPLORATION + HILL_CLIMBING + STRUCTURAL_MUTATION + CROSSOVER_HYBRID))
  if [[ $total_check -ne $TOTAL_IDEAS ]]; then
    echo "[ERROR] Strategy counts don't sum to total_ideas ($total_check != $TOTAL_IDEAS)" >&2
    echo "Check your evolution/config.yaml configuration" >&2
    exit 1
  fi
fi

# Get next generation number that doesn't have existing Python files
get_next_generation() {
  # Start with generation 1 if no CSV exists
  local start_gen=1
  
  if [[ -f "$FULL_CSV_PATH" ]]; then
    # Use Python for proper CSV parsing to find max generation
    local max_gen
    max_gen=$("$PYTHON_CMD" -c "
import csv
max_gen = 0
with open('$FULL_CSV_PATH', 'r') as f:
    reader = csv.reader(f)
    next(reader, None)  # Skip header
    for row in reader:
        if row and len(row) > 0:
            id_field = row[0].strip()
            if id_field.startswith('gen') and '-' in id_field:
                try:
                    gen_part = id_field.split('-')[0]  # e.g., 'gen01'
                    gen_num = int(gen_part[3:])  # Extract number after 'gen'
                    max_gen = max(max_gen, gen_num)
                except (ValueError, IndexError):
                    pass
print(max_gen)
")
    # Start checking from the next generation after max
    start_gen=$((max_gen + 1))
  fi
  
  # Keep incrementing until we find a generation with no Python files
  local candidate_gen=$start_gen
  while true; do
    local gen_formatted=$(printf "%02d" $candidate_gen)
    
    # Check if any Python files exist for this generation
    local py_files_exist=false
    if ls "$FULL_OUTPUT_DIR"/evolution_gen${gen_formatted}-*.py >/dev/null 2>&1; then
      py_files_exist=true
    fi
    
    if [[ "$py_files_exist" == "false" ]]; then
      # This generation is safe to use
      echo "$gen_formatted"
      return
    else
      echo "[WARN] Generation $gen_formatted already has Python files, skipping to next generation" >&2
      candidate_gen=$((candidate_gen + 1))
      
      # Safety check to prevent infinite loop
      if [[ $candidate_gen -gt 999 ]]; then
        echo "[ERROR] Could not find a safe generation number (checked up to 999)" >&2
        exit 1
      fi
    fi
  done
}

# This function is no longer used with direct CSV modification approach
# Keeping for backward compatibility but it's not called anywhere
get_next_id_number() {
  "$PYTHON_CMD" -c "
import csv
import re
max_id = 0
pattern = re.compile(r'^gen$CURRENT_GENERATION-(\d+)$')
with open('$FULL_CSV_PATH', 'r') as f:
    reader = csv.reader(f)
    next(reader, None)  # Skip header
    for row in reader:
        if row and len(row) > 0:
            match = pattern.match(row[0].strip())
            if match:
                max_id = max(max_id, int(match.group(1)))
print(max_id + 1)
"
}

# AIDEV-NOTE: This function had a critical race condition bug that caused wrong rows to be updated
# The bug occurred when parallel processes modified the main CSV between temp CSV creation and append.
# FIX: Now requires original_main_csv_lines parameter (6th arg) to track the exact line count at copy time.
# This ensures we always append the correct new rows from temp CSV, regardless of concurrent modifications.
# Without this fix, the system would update wrong IDs (e.g., claim to add gen81 but update gen80 instead).
#
# Validate that AI directly modified the CSV file
validate_direct_csv_modification() {
  local temp_csv="$1"
  local expected_count="$2"
  local idea_type="$3"
  local ai_model="${4:-}"  # AI model that generated the ideas
  local expected_ids="${5:-}"  # Optional: comma or space separated list of expected IDs
  local original_main_csv_lines="${6:-}"  # CRITICAL: Line count of main CSV when temp CSV was created

  # Check if the file was actually modified
  if [[ ! -f "$temp_csv" ]]; then
    echo "[ERROR] CSV file was not found after AI modification" >&2
    return 1
  fi

  # Count data rows in the modified temp CSV
  local new_count
  new_count=$(grep -v '^[[:space:]]*$' "$temp_csv" | tail -n +2 | wc -l | tr -d '[:space:]')

  # If original line count wasn't provided, fall back to current main CSV count (old behavior)
  # This preserves backward compatibility but may have race conditions
  if [[ -z "$original_main_csv_lines" ]]; then
    echo "[WARN] No original line count provided - using current main CSV count (may cause race conditions)" >&2
    original_main_csv_lines=$(wc -l < "$FULL_CSV_PATH" | tr -d '[:space:]')
  fi

  # Calculate how many data rows the temp CSV started with (before stubs were added)
  # This should match the original main CSV line count (including header)
  local original_data_rows=$((original_main_csv_lines - 1))  # Subtract header

  # Calculate how many rows were actually added to temp CSV
  local added_count=$((new_count - original_data_rows))

  # Check if AI overwrote the file instead of appending
  if [[ $new_count -lt $original_data_rows ]]; then
    echo "[ERROR] AI overwrote the CSV file instead of appending ($new_count < $original_data_rows)" >&2
    head -10 "$temp_csv" >&2
    return 1
  fi

  # Check if no changes were made
  if [[ $new_count -eq $original_data_rows ]]; then
    echo "[ERROR] CSV file wasn't modified - same number of data rows ($new_count = $original_data_rows)" >&2
    head -10 "$temp_csv" >&2
    return 1
  fi
  if [[ $added_count -ne $expected_count ]]; then
    echo "[ERROR] Expected to add $expected_count ideas but only added $added_count" >&2
    echo "[ERROR] Ideation failed - rejecting partial results to prevent endless loops" >&2
    rm -f "$temp_csv"
    return 1
  fi

  # If expected IDs were provided, validate that the AI used exactly those IDs
  if [[ -n "$expected_ids" ]]; then
    # Get the IDs that were actually added (last N rows of temp CSV)
    local actual_ids
    actual_ids=$(tail -n $added_count "$temp_csv" | cut -d',' -f1 | tr -d '"' | tr '\n' ' ' | xargs)

    # Normalize expected_ids (convert commas to spaces, trim)
    local expected_ids_normalized
    expected_ids_normalized=$(echo "$expected_ids" | tr ',' ' ' | xargs)

    # Compare
    if [[ "$actual_ids" != "$expected_ids_normalized" ]]; then
      echo "[ERROR] AI used wrong IDs!" >&2
      echo "[ERROR] Expected: $expected_ids_normalized" >&2
      echo "[ERROR] Actually used: $actual_ids" >&2
      echo "[ERROR] Rejecting this attempt - AI must use the exact IDs specified" >&2
      rm -f "$temp_csv"
      return 1
    fi

    echo "[INFO] ✓ AI correctly used the specified IDs: $actual_ids" >&2
  fi

  # Use proper locking to safely update the CSV
  echo "[INFO] Acquiring CSV lock to apply changes..."

  # Set the lockfile path
  CSV_LOCKFILE="$FULL_EVOLUTION_DIR/.evolution.csv.lock"

  if ! acquire_csv_lock; then
    echo "[ERROR] Failed to acquire CSV lock for update" >&2
    rm -f "$temp_csv"
    return 1
  fi

  # CRITICAL FIX: Use the original line count (when temp CSV was created) to determine which lines to append
  # This prevents race conditions where other processes modify the main CSV between temp CSV creation and append
  # Append only the NEW lines from temp CSV (those added after the original content)
  echo "[DEBUG] Appending last $added_count rows from temp CSV (from line $((original_main_csv_lines + 1)) onwards)" >&2
  tail -n +$((original_main_csv_lines + 1)) "$temp_csv" >> "$FULL_CSV_PATH"

  # Get the IDs that were actually added by reading them from temp CSV (not main CSV)
  # This avoids race conditions where other processes add rows to main CSV
  local new_ids
  new_ids=$(tail -n $added_count "$temp_csv" | grep -v "^id," | cut -d',' -f1 | tr -d '"')
  echo "[DEBUG] IDs being added: $new_ids" >&2

  # Clean up temp file
  rm -f "$temp_csv"

  # Update idea-LLM field for newly added rows if model is known
  if [[ -n "$ai_model" ]]; then
    echo "[INFO] Recording that $ai_model generated the ideas" >&2

    # Update each new row with the model that generated it
    for id in $new_ids; do
      if [[ -n "$id" && "$id" != "id" ]]; then
        echo "[DEBUG] Updating field for $id" >&2
        "$PYTHON_CMD" "$SCRIPT_DIR/../lib/evolution_csv.py" "$FULL_CSV_PATH" field "$id" "idea-LLM" "$ai_model" || echo "[WARN] Failed to update $id" >&2
      fi
    done
  fi

  # Release the lock
  release_csv_lock

  echo "[INFO] Successfully added $added_count $idea_type ideas to CSV"
  return 0
}

# DEPRECATED: Old validation function for CSV output approach
validate_and_apply_csv_modification_old() {
  local modified_csv="$1"
  local temp_csv="$2"
  local expected_count="$3"
  local idea_type="$4"
  
  # Check if the response looks like an error message (but not if it's just CSV data containing these words)
  if echo "$modified_csv" | head -1 | grep -q "id,basedOnId,description,performance,status"; then
    : # This looks like a CSV file, not an error message - continue
  elif echo "$modified_csv" | grep -qi "error\|failed\|limit\|exceeded\|sorry\|cannot\|unable"; then
    echo "[ERROR] AI failed to modify CSV and returned an error message:" >&2
    echo "$modified_csv" | head -200 >&2
    return 1
  fi
  
  # Check if response is too short to be a valid CSV
  if [[ ${#modified_csv} -lt 50 ]]; then
    echo "[ERROR] AI response is too short to be a valid CSV (${#modified_csv} chars):" >&2
    echo "$modified_csv" >&2
    return 1
  fi
  
  # Extract CSV from AI output (in case there's extra text before it)
  local csv_start_line
  csv_start_line=$(echo "$modified_csv" | grep -n "id,basedOnId,description,performance,status" | head -1 | cut -d: -f1)
  
  if [[ -n "$csv_start_line" ]]; then
    # Extract CSV starting from the header line
    modified_csv=$(echo "$modified_csv" | tail -n +$csv_start_line)
  elif ! echo "$modified_csv" | head -1 | grep -q "id,basedOnId,description,performance,status"; then
    echo "[ERROR] AI failed to return a valid CSV file. Expected CSV with header, but got:" >&2
    echo "$modified_csv" | head -c 500 >&2
    echo "" >&2
    return 1
  fi
  
  # Write the modified CSV to temp file
  echo "$modified_csv" > "$temp_csv"
  
  # Validate the modified CSV has more entries than original
  local original_count
  original_count=$(wc -l < "$FULL_CSV_PATH" | tr -d '[:space:]')
  local new_count
  new_count=$(wc -l < "$temp_csv" | tr -d '[:space:]')
  
  
  if [[ $new_count -le $original_count ]]; then
    echo "[ERROR] Modified CSV doesn't have more entries ($new_count <= $original_count)" >&2
    head -10 "$temp_csv" >&2
    return 1
  fi
  
  local added_count=$((new_count - original_count))
  if [[ $added_count -ne $expected_count ]]; then
    echo "[WARN] Expected to add $expected_count ideas but added $added_count" >&2
  fi
  
  # Use proper locking to safely update the CSV
  echo "[INFO] Acquiring CSV lock to apply changes..."
  
  # Set the lockfile path
  CSV_LOCKFILE="$FULL_EVOLUTION_DIR/.evolution.csv.lock"
  
  if ! acquire_csv_lock; then
    echo "[ERROR] Failed to acquire CSV lock for update" >&2
    rm -f "$temp_csv"
    return 1
  fi
  
  # Get just the new entries (skip header and existing entries)
  local original_line_count=$(wc -l < "$FULL_CSV_PATH" | tr -d '[:space:]')
  
  # Append only the new lines from temp CSV to the main CSV
  tail -n +$((original_line_count + 1)) "$temp_csv" >> "$FULL_CSV_PATH"
  
  # Clean up temp file
  rm -f "$temp_csv"
  
  # Update idea-LLM field for newly added rows if model is known
  if [[ -n "$ai_model" ]]; then
    echo "[INFO] Recording that $ai_model generated the ideas" >&2
    # Get the IDs of the newly added rows (skip header line and strip quotes)
    local new_ids
    new_ids=$(tail -n $added_count "$FULL_CSV_PATH" | grep -v "^id," | cut -d',' -f1 | tr -d '"')
    
    # Update each new row with the model that generated it
    for id in $new_ids; do
      if [[ -n "$id" && "$id" != "id" ]]; then
        "$PYTHON_CMD" "$SCRIPT_DIR/../lib/evolution_csv.py" "$FULL_CSV_PATH" field "$id" "idea-LLM" "$ai_model" || echo "[WARN] Failed to update $id" >&2
      fi
    done
  fi
  
  # Release the lock
  release_csv_lock
  
  echo "[INFO] Successfully added $added_count $idea_type ideas to CSV"
  return 0
}

# DEPRECATED: Old two-step process function - kept for reference
process_ai_ideas_direct_old() {
  local count="$1"
  local idea_type="$2"  # novel, hill-climbing, structural, crossover
  local top_performers="${3:-}"  # Optional, for non-novel ideas
  local ai_output="$4"  # The AI's response with ideas
  
  # Create temporary CSV copy in evolution directory (so AI can access it)
  local temp_csv="$FULL_EVOLUTION_DIR/temp-csv-$$.csv"
  cp "$FULL_CSV_PATH" "$temp_csv"
  
  
  # Build prompt for AI to directly modify the CSV
  local csv_prompt="I need you to add exactly $count new $idea_type ideas to this CSV file.

Here are the $count $idea_type ideas to add:
$ai_output

Current CSV contents:
$(cat "$temp_csv")

Instructions:
1. Add exactly $count new rows to the CSV
2. Use the next available generation numbers (gen$CURRENT_GENERATION-XXX format)
3. For each idea, create a row with: id,parent_id,description,,pending
4. CRITICAL CSV FORMATTING RULES:
   - ALWAYS wrap the description field in double quotes
   - If the description contains quotes, escape them by doubling them (\" becomes \"\")
   - Example: gen01-001,gen00-000,\"Implement adaptive RSI thresholds\",,pending
   - BAD: gen01-001,gen00-000,Implement adaptive RSI thresholds,,pending
   - NEVER omit quotes - unquoted descriptions cause CSV corruption
5. For novel ideas: leave parent_id empty
6. For other idea types: use appropriate parent IDs from these top performers:
$top_performers

IMPORTANT: Output the complete modified CSV file. Do not add any explanation or other text - just output the CSV."
  
  echo "[INFO] Having AI directly modify CSV with $count $idea_type ideas..."
  
  # Get AI to modify the CSV with fallbacks
  local modified_csv
  local stderr_file="$FULL_EVOLUTION_DIR/stderr-$$.txt"
  if ! modified_csv=$(call_ai_for_ideation "$csv_prompt" "$CURRENT_GENERATION" 2>"$stderr_file"); then
    echo "[ERROR] All AI models failed to modify CSV" >&2
    cat "$stderr_file" >&2
    rm -f "$temp_csv" "$stderr_file"
    return 1
  fi
  rm -f "$stderr_file"
  
  # Check if the response looks like an error message
  if echo "$modified_csv" | grep -qi "error\|failed\|limit\|exceeded\|sorry\|cannot\|unable"; then
    echo "[ERROR] AI failed to modify CSV and returned an error message:" >&2
    echo "$modified_csv" | head -200 >&2
    rm -f "$temp_csv" 
    return 1
  fi
  
  # Check if response is too short to be a valid CSV
  if [[ ${#modified_csv} -lt 50 ]]; then
    echo "[ERROR] AI response is too short to be a valid CSV (${#modified_csv} chars):" >&2
    echo "$modified_csv" >&2
    rm -f "$temp_csv"
    return 1
  fi
  
  # Extract CSV from AI output (in case there's extra text before it)
  local csv_start_line
  csv_start_line=$(echo "$modified_csv" | grep -n "id,basedOnId,description,performance,status" | head -1 | cut -d: -f1)
  
  if [[ -n "$csv_start_line" ]]; then
    # Extract CSV starting from the header line
    modified_csv=$(echo "$modified_csv" | tail -n +$csv_start_line)
  elif ! echo "$modified_csv" | head -1 | grep -q "id,basedOnId,description,performance,status"; then
    echo "[ERROR] AI failed to return a valid CSV file. Expected CSV with header, but got:" >&2
    echo "$modified_csv" | head -c 500 >&2
    echo "" >&2
    rm -f "$temp_csv"
    return 1
  fi
  
  # Write the modified CSV to temp file
  echo "$modified_csv" > "$temp_csv"
  
  # Debug: Show the AI's CSV modification attempt
  echo "$modified_csv" | head -c 300 >&2
  echo "" >&2
  echo "$modified_csv" | tail -c 300 >&2
  echo "" >&2
  
  # Validate the modified CSV has more entries than original
  local original_count
  original_count=$(wc -l < "$FULL_CSV_PATH" | tr -d '[:space:]')
  local new_count
  new_count=$(wc -l < "$temp_csv" | tr -d '[:space:]')
  
  
  if [[ $new_count -le $original_count ]]; then
    echo "[ERROR] Modified CSV doesn't have more entries ($new_count <= $original_count)" >&2
    cat "$temp_csv" | head -10 >&2
    cat "$FULL_CSV_PATH" | head -10 >&2
    rm -f "$temp_csv"
    return 1
  fi
  
  local added_count=$((new_count - original_count))
  if [[ $added_count -ne $count ]]; then
    echo "[WARN] Expected to add $count ideas but added $added_count" >&2
  fi
  
  # Use proper locking to safely update the CSV
  echo "[INFO] Acquiring CSV lock to apply changes..."
  
  # Set the lockfile path
  CSV_LOCKFILE="$FULL_EVOLUTION_DIR/.evolution.csv.lock"
  
  if ! acquire_csv_lock; then
    echo "[ERROR] Failed to acquire CSV lock for update" >&2
    rm -f "$temp_csv"
    return 1
  fi
  
  # Get just the new entries (skip header and existing entries)
  local original_line_count=$(wc -l < "$FULL_CSV_PATH" | tr -d '[:space:]')
  
  # Append only the new lines from temp CSV to the main CSV
  tail -n +$((original_line_count + 1)) "$temp_csv" >> "$FULL_CSV_PATH"
  
  # Clean up temp file
  rm -f "$temp_csv"
  
  # Release the lock
  release_csv_lock
  
  echo "[INFO] Successfully added $added_count $idea_type ideas to CSV"
  
  return 0
}

# Get list of existing Python files for a generation
get_existing_py_files_for_generation() {
  local generation="$1"
  local py_files=""
  
  # List all Python files for this generation
  for py_file in "$FULL_OUTPUT_DIR"/evolution_gen${generation}-*.py; do
    if [[ -f "$py_file" ]]; then
      local basename=$(basename "$py_file" .py)
      local id="${basename#evolution_}"
      if [[ -n "$py_files" ]]; then
        py_files="$py_files, $id"
      else
        py_files="$id"
      fi
    fi
  done
  
  echo "$py_files"
}

# Add existing Python files warning to prompt
add_existing_files_warning() {
  local prompt="$1"
  local generation="$2"
  local existing_py_files=$(get_existing_py_files_for_generation "$generation")
  
  if [[ -n "$existing_py_files" ]]; then
    prompt+="

WARNING: The following IDs already have Python files and MUST NOT be reused: $existing_py_files
Skip these IDs when assigning new IDs (e.g., if gen$generation-001 and gen$generation-002 exist as Python files, start with gen$generation-003)"
  fi
  
  echo "$prompt"
}

# Get next available ID for current generation
get_next_id() {
  local generation="$1"
  if [[ ! -f "$FULL_CSV_PATH" ]]; then
    echo "gen${generation}-001"
    return
  fi

  # Use Python for proper CSV parsing
  local max_id
  max_id=$("$PYTHON_CMD" -c "
import csv
import re
max_id = 0
pattern = re.compile(r'^gen${generation}-(\d+)$')
with open('$FULL_CSV_PATH', 'r') as f:
    reader = csv.reader(f)
    next(reader, None)  # Skip header
    for row in reader:
        if row and len(row) > 0:
            id_field = row[0].strip()
            match = pattern.match(id_field)
            if match:
                id_num = int(match.group(1))
                max_id = max(max_id, id_num)
print(max_id)
")

  # Format next ID with generation and 3-digit number
  printf "gen%s-%03d" "$generation" $((max_id + 1))
}

# Get the next N available IDs for current generation as a comma-separated list
get_next_ids() {
  local generation="$1"
  local count="$2"

  # Get the starting ID number
  local start_id
  if [[ ! -f "$FULL_CSV_PATH" ]]; then
    start_id=1
  else
    # Use Python for proper CSV parsing
    start_id=$("$PYTHON_CMD" -c "
import csv
import re
max_id = 0
pattern = re.compile(r'^gen${generation}-(\d+)$')
with open('$FULL_CSV_PATH', 'r') as f:
    reader = csv.reader(f)
    next(reader, None)  # Skip header
    for row in reader:
        if row and len(row) > 0:
            id_field = row[0].strip()
            match = pattern.match(id_field)
            if match:
                id_num = int(match.group(1))
                max_id = max(max_id, id_num)
print(max_id + 1)
")
  fi

  # Generate the list of IDs
  local ids=()
  for ((i=0; i<count; i++)); do
    local id_num=$((start_id + i))
    ids+=("$(printf "gen%s-%03d" "$generation" "$id_num")")
  done

  # Join with commas
  local IFS=','
  echo "${ids[*]}"
}


# Get top performers for parent selection (absolute + top novel candidates)
get_top_performers() {
  local num_requested="$1"
  if [[ ! -f "$FULL_CSV_PATH" ]]; then
    echo ""
    return
  fi
  
  # Use Python to properly parse CSV and find top performers + top novel candidates
  "$PYTHON_CMD" -c "
import csv
import sys

with open('$FULL_CSV_PATH', 'r') as f:
    reader = csv.reader(f)
    next(reader)  # Skip header
    
    completed = []
    novel = []
    
    # Collect all completed candidates
    for row in reader:
        if len(row) >= 5 and row[3] and row[4] == 'complete':
            try:
                candidate_id = row[0]
                parent_id = row[1] if len(row) > 1 else ''
                description = row[2] if len(row) > 2 else ''
                score = float(row[3])
                
                completed.append((candidate_id, description, score))
                
                # Track novel candidates separately
                if not parent_id:
                    novel.append((candidate_id, description, score))
                    
            except ValueError:
                pass
    
    # Sort absolute leaders by score (descending)
    completed.sort(key=lambda x: x[2], reverse=True)
    
    # Sort novel candidates by score (descending)
    novel.sort(key=lambda x: x[2], reverse=True)
    
    # Collect top performers
    selected_ids = set()
    results = []
    
    # Add top absolute performers
    for i, (candidate_id, description, score) in enumerate(completed[:$num_requested]):
        results.append(f'{candidate_id},{description},{score}')
        selected_ids.add(candidate_id)
    
    # Add top novel candidates (if not already selected)
    novel_count = 0
    for candidate_id, description, score in novel:
        if candidate_id not in selected_ids and novel_count < $NUM_REVOLUTION:
            results.append(f'{candidate_id},{description},{score}')
            selected_ids.add(candidate_id)
            novel_count += 1
    
    # Output all selected candidates
    for result in results:
        print(result)
"
}



# Generate ideas using AI with multi-strategy approach
ideate_ai_strategies() {
  if [[ ! -f "$FULL_BRIEF_PATH" ]]; then
    echo "[ERROR] $BRIEF_FILE not found. Run 'claude-evolve setup' first." >&2
    exit 1
  fi

  # Baseline should already be evaluated by run command

  # Get top performers (now includes top novel candidates)
  local top_performers
  top_performers=$(get_top_performers "$NUM_ELITES")
  
  if [[ -z $top_performers ]]; then
    echo "[INFO] No completed algorithms found, will use baseline algorithm for hill climbing"
    # For hill climbing and mutations, use the baseline algorithm
    # Use a special ID that validation script will recognize
    top_performers="000,Baseline Algorithm (algorithm.py),0.0"
  fi

  echo "[INFO] Generating $TOTAL_IDEAS ideas using multi-strategy approach:"
  echo "  Novel exploration: $NOVEL_EXPLORATION"
  echo "  Hill climbing: $HILL_CLIMBING" 
  echo "  Structural mutation: $STRUCTURAL_MUTATION"
  echo "  Crossover hybrid: $CROSSOVER_HYBRID"

  # Generate each type of idea by having Claude directly edit the CSV
  # Track successes - continue even if some strategies fail
  local strategies_attempted=0
  local strategies_succeeded=0
  
  if [[ $NOVEL_EXPLORATION -gt 0 ]]; then
    ((strategies_attempted++))
    if generate_novel_ideas_direct "$NOVEL_EXPLORATION"; then
      ((strategies_succeeded++))
    else
      echo "[WARN] Novel exploration strategy failed, continuing with other strategies" >&2
    fi
  fi
  
  if [[ $HILL_CLIMBING -gt 0 ]]; then
    ((strategies_attempted++))
    if generate_hill_climbing_direct "$HILL_CLIMBING" "$top_performers"; then
      ((strategies_succeeded++))
    else
      echo "[WARN] Hill climbing strategy failed, continuing with other strategies" >&2
    fi
  fi
  
  if [[ $STRUCTURAL_MUTATION -gt 0 ]]; then
    ((strategies_attempted++))
    if generate_structural_mutation_direct "$STRUCTURAL_MUTATION" "$top_performers"; then
      ((strategies_succeeded++))
    else
      echo "[WARN] Structural mutation strategy failed, continuing with other strategies" >&2
    fi
  fi
  
  if [[ $CROSSOVER_HYBRID -gt 0 ]]; then
    ((strategies_attempted++))
    if generate_crossover_direct "$CROSSOVER_HYBRID" "$top_performers"; then
      ((strategies_succeeded++))
    else
      echo "[WARN] Crossover strategy failed, continuing with other strategies" >&2
    fi
  fi
  
  echo "[INFO] Strategy results: $strategies_succeeded/$strategies_attempted succeeded" >&2

  # REQUIRE ALL strategies to succeed - no partial results
  # Accepting partial results leads to endless loops with 1 idea per generation
  if [[ $strategies_succeeded -eq $strategies_attempted ]]; then
    return 0
  else
    echo "[ERROR] Not all ideation strategies succeeded ($strategies_succeeded/$strategies_attempted)" >&2
    echo "[ERROR] Rejecting partial results - will retry with exponential backoff" >&2
    return 1
  fi
}

# Generate novel exploration ideas using direct CSV modification
generate_novel_ideas_direct() {
  local count="$1"

  # Get the next available ID BEFORE creating temp CSV
  # This ensures each strategy gets unique IDs even in parallel runs
  local next_id
  next_id=$(get_next_id "$CURRENT_GENERATION")
  echo "[INFO] Next available ID for novel ideas: $next_id" >&2

  # Generate the list of IDs this strategy should use
  local next_id_num
  next_id_num=$(echo "$next_id" | grep -o '[0-9]*$')
  # Strip leading zeros to avoid octal interpretation in arithmetic
  next_id_num=$((10#$next_id_num))
  local required_ids=()
  for ((i=0; i<count; i++)); do
    required_ids+=("$(printf "gen%s-%03d" "$CURRENT_GENERATION" $((next_id_num + i)))")
  done
  local required_ids_str="${required_ids[*]}"

  # Create temporary CSV copy in evolution directory (so AI can access it)
  local temp_csv="$FULL_EVOLUTION_DIR/temp-csv-$$.csv"
  cp "$FULL_CSV_PATH" "$temp_csv"

  # CRITICAL: Capture the original line count immediately after copying
  # This is needed to correctly append rows later, preventing race conditions
  local original_csv_lines
  original_csv_lines=$(wc -l < "$temp_csv" | tr -d '[:space:]')
  echo "[DEBUG] Original CSV has $original_csv_lines lines (including header)" >&2

  # Pre-populate the CSV with stub rows containing the correct IDs
  # This ensures the AI can't possibly use wrong IDs - it just fills in descriptions
  echo "[INFO] Pre-populating CSV with stub rows: $required_ids_str"
  for id in "${required_ids[@]}"; do
    echo "$id,,\"[PLACEHOLDER: Replace this with your algorithmic idea]\",,pending" >> "$temp_csv"
  done

  echo "[INFO] Generating $count novel exploration ideas with IDs: $required_ids_str"

  # Count total lines in temp CSV (including header)
  local total_lines
  total_lines=$(wc -l < "$temp_csv" | tr -d '[:space:]')
  local read_offset=$((total_lines - 25))
  if [[ $read_offset -lt 1 ]]; then
    read_offset=1
  fi

  # Use relative paths and change to evolution directory so AI can access files
  local temp_csv_basename=$(basename "$temp_csv")

  # Get existing Python files for this generation to avoid ID collisions
  local existing_py_files=$(get_existing_py_files_for_generation "$CURRENT_GENERATION")

  local prompt="I need you to use your file editing capabilities to fill in PLACEHOLDER descriptions in the CSV file: $temp_csv_basename

THE FILE HAS $total_lines TOTAL LINES. Read from line $read_offset to see the placeholder rows at the end.

Current evolution context:
- Generation: $CURRENT_GENERATION
- Algorithm: algorithm.py (base algorithm)
- Brief: $(head -5 "$FULL_BRIEF_PATH" 2>/dev/null | head -c 500 || echo "No brief file found")

IMPORTANT: DO NOT read algorithm.py or any evolution_*.py files. Focus on creative ideation based on the brief and CSV context only. Reading code files wastes tokens and time.

CRITICAL TASK:
The CSV file already contains $count stub rows with these IDs: $required_ids_str
Each stub row has a PLACEHOLDER description like: \"[PLACEHOLDER: Replace this with your algorithmic idea]\"
Your job is to REPLACE each PLACEHOLDER with a real algorithmic idea description.

⚠️ CRITICAL FILE READING INSTRUCTIONS ⚠️
THE CSV FILE IS VERY LARGE (OVER 100,000 TOKENS). YOU WILL RUN OUT OF CONTEXT IF YOU READ IT ALL!
- DO NOT read the entire file or you will exceed context limits and CRASH
- Use: Read(file_path='$temp_csv_basename', offset=$read_offset, limit=25)
- This will read ONLY the last 25 lines where the placeholders are
- DO NOT READ FROM OFFSET 0 - that will load the entire huge file and fail!

CRITICAL INSTRUCTIONS:
1. Read ONLY the last 20-30 lines of the CSV to see the placeholder rows
2. DO NOT ADD OR DELETE ANY ROWS - only EDIT the placeholder descriptions
3. DO NOT CHANGE THE IDs - they are already correct ($required_ids_str)
4. Use the Edit tool to replace EACH PLACEHOLDER text with a real algorithmic idea
5. When editing, preserve the CSV structure: keep the ID and parent_id fields unchanged"

  if [[ -n "$existing_py_files" ]]; then
    prompt+="
6. IMPORTANT: The following IDs already have Python files: $existing_py_files
   (This is informational only - use the IDs specified above)"
  fi

  prompt+="
7. CRITICAL CSV FORMATTING RULES:
   - ALWAYS wrap the description field in double quotes
   - If the description contains quotes, escape them by doubling them (\" becomes \"\")
   - Example: gen01-001,,\"Implement adaptive RSI thresholds based on volatility\",,pending
   - BAD: gen01-001,,Implement adaptive RSI thresholds based on volatility,,pending
   - NEVER omit quotes around descriptions - this causes CSV parsing errors
9. Each description should be one clear sentence describing a novel algorithmic approach
10. Focus on creative, ambitious ideas that haven't been tried yet
11. Consider machine learning, new indicators, regime detection, risk management, etc.

IMPORTANT: You must APPEND new rows to the existing CSV file. DO NOT replace the file contents. All existing rows must remain unchanged.
CRITICAL: You must use your file editing tools (Edit/MultiEdit) to modify the CSV file. DO NOT return CSV text - use your tools to edit the file directly.
CRITICAL: Do NOT use any git commands (git add, git commit, git reset, etc.). Only modify the file directly."

  # Debug prompt size and context (removed - no longer needed)

  # Change to evolution directory so AI can access files
  local original_pwd=$(pwd)
  cd "$FULL_EVOLUTION_DIR"
  
  # Debug: Show files in evolution directory
  
  # Get AI to directly edit the CSV file
  local ai_response
  local stderr_file="stderr-$$.txt"
  # Temporarily show stderr for debugging
  if ! ai_response=$(call_ai_for_ideation "$prompt" "$CURRENT_GENERATION" "$count" "$temp_csv_basename"); then
    echo "[ERROR] All AI models failed to generate novel ideas" >&2
    cat "$stderr_file" >&2
    cd "$original_pwd"
    rm -f "$temp_csv" "$stderr_file"
    return 1
  fi
  rm -f "$stderr_file"
  
  # Restore working directory
  cd "$original_pwd"

  # Validate that the CSV file was actually modified with correct IDs
  # Pass original_csv_lines to prevent race conditions
  if ! validate_direct_csv_modification "$temp_csv" "$count" "novel" "$ai_response" "$required_ids_str" "$original_csv_lines"; then
    rm -f "$temp_csv"
    return 1
  fi

  echo "[INFO] Novel exploration ideas generated successfully"
  return 0
}

# Generate hill climbing ideas using direct CSV modification
generate_hill_climbing_direct() {
  local count="$1"
  local top_performers="$2"

  # Get the next available ID BEFORE creating temp CSV
  local next_id
  next_id=$(get_next_id "$CURRENT_GENERATION")
  echo "[INFO] Next available ID for hill climbing: $next_id" >&2

  # Generate the list of IDs this strategy should use
  local next_id_num
  next_id_num=$(echo "$next_id" | grep -o '[0-9]*$')
  # Strip leading zeros to avoid octal interpretation in arithmetic
  next_id_num=$((10#$next_id_num))
  local required_ids=()
  for ((i=0; i<count; i++)); do
    required_ids+=("$(printf "gen%s-%03d" "$CURRENT_GENERATION" $((next_id_num + i)))")
  done
  local required_ids_str="${required_ids[*]}"

  # Create temporary CSV copy in evolution directory (so AI can access it)
  local temp_csv="$FULL_EVOLUTION_DIR/temp-csv-$$.csv"
  cp "$FULL_CSV_PATH" "$temp_csv"

  # CRITICAL: Capture the original line count immediately after copying
  local original_csv_lines
  original_csv_lines=$(wc -l < "$temp_csv" | tr -d '[:space:]')
  echo "[DEBUG] Original CSV has $original_csv_lines lines (including header)" >&2

  # Extract just the IDs from top performers for clarity (needed before pre-populating)
  local valid_parent_ids
  valid_parent_ids=$(echo "$top_performers" | cut -d',' -f1 | paste -sd ',' -)

  # Pre-populate the CSV with stub rows containing the correct IDs and parent IDs
  echo "[INFO] Pre-populating CSV with stub rows: $required_ids_str"
  # Use first parent as default for stubs (AI will adjust if needed)
  local first_parent_id
  first_parent_id=$(echo "$valid_parent_ids" | cut -d',' -f1)
  for id in "${required_ids[@]}"; do
    echo "$id,$first_parent_id,\"[PLACEHOLDER: Replace with parameter tuning idea]\",,pending" >> "$temp_csv"
  done

  echo "[INFO] Generating $count hill climbing ideas with IDs: $required_ids_str"

  # Count total lines in temp CSV (including header)
  local total_lines
  total_lines=$(wc -l < "$temp_csv" | tr -d '[:space:]')
  local read_offset=$((total_lines - 25))
  if [[ $read_offset -lt 1 ]]; then
    read_offset=1
  fi

  # Get existing Python files for this generation to avoid ID collisions
  local existing_py_files=$(get_existing_py_files_for_generation "$CURRENT_GENERATION")

  # Use relative paths and change to evolution directory so AI can access files
  local temp_csv_basename=$(basename "$temp_csv")

  local prompt="I need you to use your file editing capabilities to fill in PLACEHOLDER descriptions in the CSV file: $temp_csv_basename

THE FILE HAS $total_lines TOTAL LINES. Read from line $read_offset to see the placeholder rows at the end.

IMPORTANT: You MUST use one of these exact parent IDs: $valid_parent_ids

Successful algorithms to tune:
$top_performers

IMPORTANT: Generate parameter tuning ideas based primarily on the descriptions and scores above.

ONLY read parent source files (evolution_<PARENT_ID>.py) if:
- The description is too vague to identify specific parameters
- You need to verify actual parameter names/values
- Reading is absolutely necessary for meaningful tuning

If you must read source files:
- Read in small chunks (offset/limit) to minimize token usage
- Focus only on finding parameter definitions at the top of the file
- Do NOT read the entire implementation

Most of the time, you can infer parameters from descriptions like "RSI with threshold 30" or "MA period 20".

CRITICAL TASK:
The CSV file already contains $count stub rows with these IDs: $required_ids_str
Each stub row has a PLACEHOLDER description like: \"[PLACEHOLDER: Replace with parameter tuning idea]\"
Your job is to REPLACE each PLACEHOLDER with a real parameter tuning idea.

⚠️ CRITICAL FILE READING INSTRUCTIONS ⚠️
THE CSV FILE IS VERY LARGE (OVER 100,000 TOKENS). YOU WILL RUN OUT OF CONTEXT IF YOU READ IT ALL!
- DO NOT read the entire file or you will exceed context limits and CRASH
- Use: Read(file_path='$temp_csv_basename', offset=$read_offset, limit=25)
- This will read ONLY the last 25 lines where the placeholders are
- DO NOT READ FROM OFFSET 0 - that will load the entire huge file and fail!

CRITICAL INSTRUCTIONS:
1. Read ONLY the last 25 lines using the offset specified above
2. DO NOT ADD OR DELETE ANY ROWS - only EDIT the placeholder descriptions
3. DO NOT CHANGE THE IDs - they are already correct ($required_ids_str)
4. Use the Edit tool to replace EACH PLACEHOLDER text with a parameter tuning idea
5. When editing, preserve the CSV structure: keep the ID field unchanged
6. You may change the parent_id field if needed to reference a different top performer
7. Each description should focus on adjusting specific parameters - include current and new values
   Example: \"Lower rsi_entry from 21 to 18\" or \"Increase MA period from 20 to 50\"
8. CRITICAL: When editing, preserve the CSV formatting with proper quoting
9. DO NOT use any git commands (git add, git commit, git reset, etc.). Only modify the file directly."

  # Change to evolution directory so AI can access files
  local original_pwd=$(pwd)
  cd "$FULL_EVOLUTION_DIR"
  
  # Get AI to directly edit the CSV file
  local ai_response
  local stderr_file="stderr-$$.txt"
  # Temporarily show stderr for debugging
  if ! ai_response=$(call_ai_for_ideation "$prompt" "$CURRENT_GENERATION" "$count" "$temp_csv_basename"); then
    echo "[ERROR] All AI models failed to generate hill climbing ideas" >&2
    cat "$stderr_file" >&2
    cd "$original_pwd"
    rm -f "$temp_csv" "$stderr_file"
    return 1
  fi
  rm -f "$stderr_file"
  
  # Restore working directory
  cd "$original_pwd"

  # Validate that the CSV file was actually modified with correct IDs
  # Pass original_csv_lines to prevent race conditions
  if ! validate_direct_csv_modification "$temp_csv" "$count" "hill-climbing" "$ai_response" "$required_ids_str" "$original_csv_lines"; then
    rm -f "$temp_csv"
    return 1
  fi

  echo "[INFO] Hill climbing ideas generated successfully"
  return 0
}

# Generate structural mutation ideas using direct CSV modification
generate_structural_mutation_direct() {
  local count="$1"
  local top_performers="$2"

  # Get the next available ID BEFORE creating temp CSV
  local next_id
  next_id=$(get_next_id "$CURRENT_GENERATION")
  echo "[INFO] Next available ID for structural mutation: $next_id" >&2

  # Generate the list of IDs this strategy should use
  local next_id_num
  next_id_num=$(echo "$next_id" | grep -o '[0-9]*$')
  # Strip leading zeros to avoid octal interpretation in arithmetic
  next_id_num=$((10#$next_id_num))
  local required_ids=()
  for ((i=0; i<count; i++)); do
    required_ids+=("$(printf "gen%s-%03d" "$CURRENT_GENERATION" $((next_id_num + i)))")
  done
  local required_ids_str="${required_ids[*]}"

  # Create temporary CSV copy in evolution directory (so AI can access it)
  local temp_csv="$FULL_EVOLUTION_DIR/temp-csv-$$.csv"
  cp "$FULL_CSV_PATH" "$temp_csv"

  # CRITICAL: Capture the original line count immediately after copying
  local original_csv_lines
  original_csv_lines=$(wc -l < "$temp_csv" | tr -d '[:space:]')
  echo "[DEBUG] Original CSV has $original_csv_lines lines (including header)" >&2

  # Extract just the IDs from top performers for clarity (needed before pre-populating)
  local valid_parent_ids
  valid_parent_ids=$(echo "$top_performers" | cut -d',' -f1 | paste -sd ',' -)

  # Pre-populate the CSV with stub rows
  echo "[INFO] Pre-populating CSV with stub rows: $required_ids_str"
  local first_parent_id
  first_parent_id=$(echo "$valid_parent_ids" | cut -d',' -f1)
  for id in "${required_ids[@]}"; do
    echo "$id,$first_parent_id,\"[PLACEHOLDER: Replace with structural modification idea]\",,pending" >> "$temp_csv"
  done

  echo "[INFO] Generating $count structural mutation ideas with IDs: $required_ids_str"

  # Count total lines in temp CSV (including header)
  local total_lines
  total_lines=$(wc -l < "$temp_csv" | tr -d '[:space:]')
  local read_offset=$((total_lines - 25))
  if [[ $read_offset -lt 1 ]]; then
    read_offset=1
  fi

  # Get existing Python files for this generation to avoid ID collisions
  local existing_py_files=$(get_existing_py_files_for_generation "$CURRENT_GENERATION")

  # Use relative paths and change to evolution directory so AI can access files
  local temp_csv_basename=$(basename "$temp_csv")

  local prompt="I need you to use your file editing capabilities to fill in PLACEHOLDER descriptions in the CSV file: $temp_csv_basename

THE FILE HAS $total_lines TOTAL LINES. Read from line $read_offset to see the placeholder rows at the end.

IMPORTANT: You MUST use one of these exact parent IDs: $valid_parent_ids

Successful algorithms to modify structurally:
$top_performers

IMPORTANT: DO NOT read evolution_*.py files. Generate structural ideas based ONLY on:
- The algorithm descriptions above
- The performance scores
- Your knowledge of common algorithmic structures and patterns
Reading code files wastes tokens and time. Focus on high-level architectural ideas based on the descriptions.

CRITICAL TASK:
The CSV file already contains $count stub rows with these IDs: $required_ids_str
Each stub row has a PLACEHOLDER description like: \"[PLACEHOLDER: Replace with structural modification idea]\"
Your job is to REPLACE each PLACEHOLDER with a real structural modification idea.

⚠️ CRITICAL FILE READING INSTRUCTIONS ⚠️
THE CSV FILE IS VERY LARGE (OVER 100,000 TOKENS). YOU WILL RUN OUT OF CONTEXT IF YOU READ IT ALL!
- DO NOT read the entire file or you will exceed context limits and CRASH
- Use: Read(file_path='$temp_csv_basename', offset=$read_offset, limit=25)
- This will read ONLY the last 25 lines where the placeholders are
- DO NOT READ FROM OFFSET 0 - that will load the entire huge file and fail!

CRITICAL INSTRUCTIONS:
1. Read ONLY the last 25 lines using the offset specified above
2. DO NOT ADD OR DELETE ANY ROWS - only EDIT the placeholder descriptions
3. DO NOT CHANGE THE IDs - they are already correct ($required_ids_str)
4. Use the Edit tool to replace EACH PLACEHOLDER text with a structural modification idea
5. When editing, preserve the CSV structure: keep the ID field unchanged
6. You may change the parent_id field if needed to reference a different top performer
7. Each description should focus on architectural/structural changes
8. CRITICAL: When editing, preserve the CSV formatting with proper quoting
9. DO NOT use any git commands (git add, git commit, git reset, etc.). Only modify the file directly."

  # Change to evolution directory so AI can access files
  local original_pwd=$(pwd)
  cd "$FULL_EVOLUTION_DIR"
  
  # Get AI to directly edit the CSV file
  local ai_response
  local stderr_file="stderr-$$.txt"
  # Temporarily show stderr for debugging
  if ! ai_response=$(call_ai_for_ideation "$prompt" "$CURRENT_GENERATION" "$count" "$temp_csv_basename"); then
    echo "[ERROR] All AI models failed to generate structural mutation ideas" >&2
    cat "$stderr_file" >&2
    cd "$original_pwd"
    rm -f "$temp_csv" "$stderr_file"
    return 1
  fi
  rm -f "$stderr_file"
  
  # Restore working directory
  cd "$original_pwd"

  # Validate that the CSV file was actually modified with correct IDs
  # Pass original_csv_lines to prevent race conditions
  if ! validate_direct_csv_modification "$temp_csv" "$count" "structural" "$ai_response" "$required_ids_str" "$original_csv_lines"; then
    rm -f "$temp_csv"
    return 1
  fi

  echo "[INFO] Structural mutation ideas generated successfully"
  return 0
}

# Generate crossover hybrid ideas using direct CSV modification
generate_crossover_direct() {
  local count="$1"
  local top_performers="$2"

  # Get the next available ID BEFORE creating temp CSV
  local next_id
  next_id=$(get_next_id "$CURRENT_GENERATION")
  echo "[INFO] Next available ID for crossover: $next_id" >&2

  # Generate the list of IDs this strategy should use
  local next_id_num
  next_id_num=$(echo "$next_id" | grep -o '[0-9]*$')
  # Strip leading zeros to avoid octal interpretation in arithmetic
  next_id_num=$((10#$next_id_num))
  local required_ids=()
  for ((i=0; i<count; i++)); do
    required_ids+=("$(printf "gen%s-%03d" "$CURRENT_GENERATION" $((next_id_num + i)))")
  done
  local required_ids_str="${required_ids[*]}"

  # Create temporary CSV copy in evolution directory (so AI can access it)
  local temp_csv="$FULL_EVOLUTION_DIR/temp-csv-$$.csv"
  cp "$FULL_CSV_PATH" "$temp_csv"

  # CRITICAL: Capture the original line count immediately after copying
  local original_csv_lines
  original_csv_lines=$(wc -l < "$temp_csv" | tr -d '[:space:]')
  echo "[DEBUG] Original CSV has $original_csv_lines lines (including header)" >&2

  # Extract just the IDs from top performers for clarity (needed before pre-populating)
  local valid_parent_ids
  valid_parent_ids=$(echo "$top_performers" | cut -d',' -f1 | paste -sd ',' -)

  # Pre-populate the CSV with stub rows
  echo "[INFO] Pre-populating CSV with stub rows: $required_ids_str"
  local first_parent_id
  first_parent_id=$(echo "$valid_parent_ids" | cut -d',' -f1)
  for id in "${required_ids[@]}"; do
    echo "$id,$first_parent_id,\"[PLACEHOLDER: Replace with crossover hybrid idea]\",,pending" >> "$temp_csv"
  done

  echo "[INFO] Generating $count crossover hybrid ideas with IDs: $required_ids_str"

  # Count total lines in temp CSV (including header)
  local total_lines
  total_lines=$(wc -l < "$temp_csv" | tr -d '[:space:]')
  local read_offset=$((total_lines - 25))
  if [[ $read_offset -lt 1 ]]; then
    read_offset=1
  fi

  # Get existing Python files for this generation to avoid ID collisions
  local existing_py_files=$(get_existing_py_files_for_generation "$CURRENT_GENERATION")

  # Use relative paths and change to evolution directory so AI can access files
  local temp_csv_basename=$(basename "$temp_csv")

  local prompt="I need you to use your file editing capabilities to fill in PLACEHOLDER descriptions in the CSV file: $temp_csv_basename

THE FILE HAS $total_lines TOTAL LINES. Read from line $read_offset to see the placeholder rows at the end.

IMPORTANT: You MUST use ONLY these exact parent IDs: $valid_parent_ids

Top performers to combine (reference at least 2 in each idea):
$top_performers

IMPORTANT: DO NOT read evolution_*.py files. Generate crossover ideas based ONLY on:
- The algorithm descriptions above (which describe their key features)
- The performance scores
- Your knowledge of how different algorithmic approaches can be combined
Reading code files wastes tokens and time. Focus on combining the described features creatively.

CRITICAL TASK:
The CSV file already contains $count stub rows with these IDs: $required_ids_str
Each stub row has a PLACEHOLDER description like: \"[PLACEHOLDER: Replace with crossover hybrid idea]\"
Your job is to REPLACE each PLACEHOLDER with a real crossover/hybrid idea that combines 2+ algorithms.

⚠️ CRITICAL FILE READING INSTRUCTIONS ⚠️
THE CSV FILE IS VERY LARGE (OVER 100,000 TOKENS). YOU WILL RUN OUT OF CONTEXT IF YOU READ IT ALL!
- DO NOT read the entire file or you will exceed context limits and CRASH
- Use: Read(file_path='$temp_csv_basename', offset=$read_offset, limit=25)
- This will read ONLY the last 25 lines where the placeholders are
- DO NOT READ FROM OFFSET 0 - that will load the entire huge file and fail!

CRITICAL INSTRUCTIONS:
1. Read ONLY the last 25 lines using the offset specified above
2. DO NOT ADD OR DELETE ANY ROWS - only EDIT the placeholder descriptions
3. DO NOT CHANGE THE IDs - they are already correct ($required_ids_str)
4. Use the Edit tool to replace EACH PLACEHOLDER text with a crossover idea
5. When editing, preserve the CSV structure: keep the ID field unchanged
6. You may change the parent_id field if needed (choose the primary parent)
7. Each description should combine actual elements from 2+ top performers
8. CRITICAL: When editing, preserve the CSV formatting with proper quoting
9. DO NOT use any git commands (git add, git commit, git reset, etc.). Only modify the file directly."

  # Change to evolution directory so AI can access files
  local original_pwd=$(pwd)
  cd "$FULL_EVOLUTION_DIR"
  
  # Get AI to directly edit the CSV file
  local ai_response
  local stderr_file="stderr-$$.txt"
  # Temporarily show stderr for debugging
  if ! ai_response=$(call_ai_for_ideation "$prompt" "$CURRENT_GENERATION" "$count" "$temp_csv_basename"); then
    echo "[ERROR] All AI models failed to generate crossover hybrid ideas" >&2
    cat "$stderr_file" >&2
    cd "$original_pwd"
    rm -f "$temp_csv" "$stderr_file"
    return 1
  fi
  rm -f "$stderr_file"
  
  # Restore working directory
  cd "$original_pwd"

  # Validate that the CSV file was actually modified with correct IDs
  # Pass original_csv_lines to prevent race conditions
  if ! validate_direct_csv_modification "$temp_csv" "$count" "crossover" "$ai_response" "$required_ids_str" "$original_csv_lines"; then
    rm -f "$temp_csv"
    return 1
  fi

  echo "[INFO] Crossover hybrid ideas generated successfully"
  return 0
}

# Legacy AI generation mode (for backward compatibility)
ideate_ai_legacy() {
  if [[ ! -f "$FULL_BRIEF_PATH" ]]; then
    echo "[ERROR] $BRIEF_FILE not found. Run 'claude-evolve setup' first." >&2
    exit 1
  fi

  # Create temporary CSV copy in evolution directory (so AI can access it)
  local temp_csv="$FULL_EVOLUTION_DIR/temp-csv-$$.csv"
  cp "$FULL_CSV_PATH" "$temp_csv"

  # CRITICAL: Capture the original line count immediately after copying
  local original_csv_lines
  original_csv_lines=$(wc -l < "$temp_csv" | tr -d '[:space:]')
  echo "[DEBUG] Original CSV has $original_csv_lines lines (including header)" >&2

  echo "[INFO] Generating $TOTAL_IDEAS ideas (legacy mode)..."

  # Get top performers for context
  local top_performers=""
  if [[ -f "$FULL_CSV_PATH" ]]; then
    # Simple top performers extraction (lines with non-empty performance)
    top_performers=$(awk -F, 'NR > 1 && $4 != "" { print $1 ": " $3 " (score: " $4 ")" }' "$FULL_CSV_PATH" | head -5)
  fi

  # Build prompt for direct CSV modification
  # Use relative paths and change to evolution directory so AI can access files
  local temp_csv_basename=$(basename "$temp_csv")
  
  local prompt="I need you to use your file editing capabilities to add exactly $TOTAL_IDEAS algorithmic ideas to the CSV file: $temp_csv_basename

Current evolution context:
- Generation: $CURRENT_GENERATION
- Algorithm: algorithm.py (base algorithm)
- Brief: $(head -10 "$FULL_BRIEF_PATH" 2>/dev/null | head -c 1000 || echo "No brief file found")

IMPORTANT: DO NOT read algorithm.py or any evolution_*.py files - that uses too many tokens and is unnecessary for ideation. Just generate creative ideas based on the brief and top performers listed above. Focus your creativity on the problem space, not the implementation details."

  if [[ -n $top_performers ]]; then
    prompt+="

Top Performing Algorithms So Far:
$top_performers"
  fi

  prompt+="

CRITICAL INSTRUCTIONS:
1. Use the Read tool to examine the current CSV file
   IMPORTANT: If the CSV file is large (>200 lines), read it in chunks using the offset and limit parameters to avoid context overload
   Example: Read(file_path='temp-csv-123.csv', offset=0, limit=100) then Read(offset=100, limit=100), etc.
2. DO NOT DELETE OR REPLACE ANY EXISTING ROWS - YOU MUST PRESERVE ALL EXISTING DATA
3. Find the highest ID number for generation $CURRENT_GENERATION (e.g., if gen$CURRENT_GENERATION-003 exists, next should be gen$CURRENT_GENERATION-004)
4. If no gen$CURRENT_GENERATION entries exist yet, start with gen$CURRENT_GENERATION-001
5. Use the Edit or MultiEdit tool to APPEND exactly $TOTAL_IDEAS new rows AT THE END of the CSV file
6. For each idea, create a row with: id,parent_id,description,,pending
7. CRITICAL CSV FORMATTING RULES:
   - ALWAYS wrap the description field in double quotes
   - If the description contains quotes, escape them by doubling them (\" becomes \"\")
   - Example: gen01-001,gen00-000,\"Implement adaptive RSI thresholds based on volatility\",,pending
   - BAD: gen01-001,gen00-000,Implement adaptive RSI thresholds based on volatility,,pending
   - NEVER omit quotes around descriptions - this causes CSV parsing errors that corrupt the data
8. Mix both parameter tuning and structural changes
9. If building on existing algorithms, use their ID as parent_id, otherwise leave parent_id empty

⚠️ AVOID ONLY: Kelly floor/cap adjustments that assume leverage > 1.0 (these get clamped and have no effect)

✅ EXPLORE ALL CREATIVE POSSIBILITIES INCLUDING:
- Machine Learning: Neural networks, ensemble methods, reinforcement learning (use train() method)
- Advanced Indicators: Custom combinations, multi-timeframe signals, cross-asset indicators
- Market Regime Detection: VIX patterns, correlation analysis, volatility clustering
- Risk Management: Dynamic stops, portfolio heat, correlation-based position sizing
- Alternative Strategies: New sub-strategies, momentum variants, mean reversion innovations
- Multi-Asset Signals: Sector rotation, bond yields, commodity signals
- Time-Based Patterns: Intraday effects, calendar anomalies, volatility timing
- Parameter Optimization: Entry thresholds, indicator periods, strategy weights

IMPORTANT: You must APPEND new rows to the existing CSV file. DO NOT replace the file contents. All existing rows must remain unchanged.
CRITICAL: You must use your file editing tools (Edit/MultiEdit) to modify the CSV file. DO NOT return CSV text - use your tools to edit the file directly.
CRITICAL: Do NOT use any git commands (git add, git commit, git reset, etc.). Only modify the file directly."

  # Change to evolution directory so AI can access files
  local original_pwd=$(pwd)
  cd "$FULL_EVOLUTION_DIR"
  
  # Get AI to directly edit the CSV file
  local ai_response
  local stderr_file="stderr-$$.txt"
  if ! ai_response=$(call_ai_for_ideation "$prompt" "$CURRENT_GENERATION" "$TOTAL_IDEAS" "$temp_csv_basename" 2>"$stderr_file"); then
    echo "[ERROR] All AI models failed to generate ideas" >&2
    cat "$stderr_file" >&2
    cd "$original_pwd"
    rm -f "$temp_csv" "$stderr_file"
    return 1
  fi
  rm -f "$stderr_file"
  
  # Restore working directory
  cd "$original_pwd"

  # Validate that the CSV file was actually modified
  # Pass original_csv_lines to prevent race conditions
  if ! validate_direct_csv_modification "$temp_csv" "$TOTAL_IDEAS" "mixed" "$ai_response" "" "$original_csv_lines"; then
    rm -f "$temp_csv"
    return 1
  fi

  echo "[INFO] Legacy ideas generated"
  return 0
}

# Determine generation number for this ideation run
CURRENT_GENERATION=$(get_next_generation)
echo "[INFO] Starting ideation for generation $CURRENT_GENERATION"

# Main execution with retry logic and exponential backoff
retry_count=0
wait_seconds=300  # Start with 5 minutes
max_wait_seconds=1800  # Cap at 30 minutes

while true; do
  if [[ $use_strategies == true ]]; then
    echo "[INFO] Multi-strategy AI generation mode"
    if ideate_ai_strategies; then
      echo "[INFO] Ideation complete! Check $EVOLUTION_CSV for new ideas."
      exit 0
    fi
  else
    echo "[INFO] Legacy AI generation mode"
    if ideate_ai_legacy; then
      echo "[INFO] Ideation complete! Check $EVOLUTION_CSV for new ideas."
      exit 0
    fi
  fi

  # If we reach here, ideation failed
  ((retry_count++))

  echo "[WARN] All ideation attempts failed (retry #$retry_count)" >&2
  echo "[INFO] This could be temporary API rate limits or service issues" >&2
  echo "[INFO] Waiting $wait_seconds seconds ($(($wait_seconds / 60)) minutes) before retrying..." >&2

  # Sleep with countdown
  remaining=$wait_seconds
  while [[ $remaining -gt 0 ]]; do
    if [[ $((remaining % 60)) -eq 0 ]]; then
      echo "[INFO] Retrying in $((remaining / 60)) minutes..." >&2
    fi
    sleep 60
    remaining=$((remaining - 60))
  done

  echo "[INFO] Retrying ideation (attempt #$((retry_count + 1)))..." >&2

  # Exponential backoff: double the wait time, up to max
  wait_seconds=$((wait_seconds * 2))
  if [[ $wait_seconds -gt $max_wait_seconds ]]; then
    wait_seconds=$max_wait_seconds
  fi
done