# claude-evolve configuration file
# This file defines paths and settings for the evolution process
# 
# NOTE: The evolution directory is automatically inferred from this config file's location.
# For example, if this file is at /path/to/my-experiment/config.yaml,
# then the evolution directory will be /path/to/my-experiment/

# Algorithm and evaluator file paths (relative to evolution directory)
algorithm_file: "algorithm.py"
evaluator_file: "evaluator.py"
brief_file: "BRIEF.md"

# CSV file for tracking evolution (relative to evolution directory)
evolution_csv: "evolution.csv"

# Output directory for generated algorithms (relative to evolution directory)
# Leave empty to use evolution directory directly
output_dir: ""

# Parent algorithm selection strategy
# Options: "best", "random", "latest"
parent_selection: "best"

# Multi-strategy ideation configuration
ideation_strategies:
  # Total ideas per generation
  total_ideas: 15
  
  # Strategy distribution (must sum to total_ideas)
  novel_exploration: 3      # Pure creativity, global search
  hill_climbing: 5          # Parameter tuning of top performers
  structural_mutation: 3    # Algorithmic changes to top performers
  crossover_hybrid: 4       # Combine successful approaches
  
  # Number of top performers to use as parents
  num_elites: 3

# Python command to use for evaluation
python_cmd: "python3"

# Auto ideation configuration
# When true, automatically generate new ideas when no pending candidates remain
auto_ideate: true

# Retry configuration
# Maximum number of retries for failed candidates before marking as permanently failed
max_retries: 3

# Memory protection configuration
# Memory limit in MB for evaluation processes (0 = no limit)  
# This prevents runaway algorithms from consuming all system memory
# Default: 12GB (reasonable for ML workloads, adjust based on your system RAM)
# Recommendation: Set to ~50-75% of available system RAM
memory_limit_mb: 12288

# Worker refresh configuration
# Workers will automatically exit after processing this many candidates
# This allows them to pick up library updates without manual restarts
# Lower values = more frequent refreshes, higher values = less overhead
# Recommended: 1-5 for development, 10-20 for production
worker_max_candidates: 3

# Parallel execution configuration
parallel:
  # Enable parallel execution of evolution candidates
  enabled: false
  
  # Maximum number of worker processes to run simultaneously
  max_workers: 4
  
  # Timeout in seconds when waiting for CSV locks
  lock_timeout: 30

# LLM/AI CLI configuration
llm_cli:
  # What to run for each sub-command
  # Models are tried in order, with round-robin distribution across candidates
  # You can repeat models for weighted selection (e.g., "sonnet sonnet gemini" for 2:1 ratio)

  # Default configuration: 100% local code generation, commercial ideation + local fallback
  # Commented out because these change over time; uncomment to override
  #run: codex-qwen3
  #ideate: opus-openrouter kimi-k2-think-moonshot gemini-pro sonnet-think gpt5high grok-4-openrouter deepseek-openrouter glm-zai

  # Available models:
  # - sonnet: Claude 3.5 Sonnet via Claude CLI
  # - sonnet-think: Claude 3.5 Sonnet with extended thinking (ultrathink prompt)
  # - opus: Claude 3 Opus via Claude CLI
  # - opus-think: Claude 3 Opus with extended thinking (ultrathink prompt)
  # - gemini: Gemini via Gemini CLI
  # - gpt5: GPT-5 via Codex CLI (standard)
  # - gpt5high: GPT-5 via Codex CLI (high reasoning)
  # - o3high: O3 via Codex CLI (high reasoning)
  # - cursor-sonnet: Claude 3.5 Sonnet via Cursor Agent CLI
  # - cursor-opus: Claude 3 Opus via Cursor Agent CLI
  # - glm: GLM-4.6 via OpenCode CLI
  # - grok-code-fast: Grok Code Fast 1 via OpenRouter
  # - grok-4: Grok 4 via OpenRouter
  # - opus-openrouter: Claude Opus 4.1 via OpenRouter
  # - kimi-k2-think-moonshot: Kimi K2 Thinking via Moonshot
  # - codex-qwen3: Qwen3-Coder via Codex + Ollama (local, free, RECOMMENDED)
  # - aider-qwen3: Qwen3-Coder via Aider + Ollama (local, free, experimental)
